{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Lexos Corpus Module\n",
    "\n",
    "This comprehensive tutorial will guide you through the corpus module, showing you how to manage document collections, perform statistical analysis, and integrate with other Lexos modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Setup\n",
    "\n",
    "First, let's import everything you'll need and set up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lexos imports\n",
    "from lexos.corpus import Corpus, Record\n",
    "from lexos.corpus.corpus_stats import CorpusStats\n",
    "from lexos.io import Loader  # For UTF-8 compliant file loading\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*Expected `str` but got `UUID`.*\")\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Managing a Corpus\n",
    "\n",
    "A corpus is a collection of documents that you want to analyze together. Let's create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS: Replace with your project name and directory\n",
    "corpus_name = \"My Research Corpus\"  # Your project name\n",
    "corpus_directory = tempfile.mkdtemp()  # Or use a permanent directory like \"./my_corpus\"\n",
    "\n",
    "# Create the corpus\n",
    "corpus = Corpus(\n",
    "    name=corpus_name,\n",
    "    corpus_dir=corpus_directory\n",
    ")\n",
    "\n",
    "print(f\"üìö Created corpus: {corpus.name}\")\n",
    "print(f\"üìÅ Storage location: {corpus.corpus_dir}\")\n",
    "print(f\"üìä Current state:\")\n",
    "print(f\"   - Documents: {corpus.num_docs}\")\n",
    "print(f\"   - Active documents: {corpus.num_active_docs}\")\n",
    "print(f\"   - Total tokens: {corpus.num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Documents\n",
    "\n",
    "Now let's add your documents to the corpus. You can add documents from text strings, files, or any other source. Note that we created the corpus in the previous cell. If you run multiple cells below (or the same cells multiple times), new records will be added to the existing corpus.\n",
    "\n",
    "### Option A: Add From Text Strings\n",
    "\n",
    "The cell below provides a dictionary of sample texts with text names as the keys and the text strings as the values. You can replace them with your own texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = {\n",
    "    \"sample_literature\": \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.\",\n",
    "    \"sample_academic\": \"The rapid advancement of artificial intelligence has profound implications for various sectors of society. Machine learning algorithms are increasingly being deployed in healthcare, finance, and education, raising important questions about accountability, transparency, and fairness in automated decision-making systems.\",\n",
    "    \"sample_news\": \"Local authorities announced today that the new community center will open next month. The facility will feature a library, gymnasium, and meeting spaces for local organizations. Residents have been eagerly anticipating the opening since construction began two years ago.\",\n",
    "    \"sample_dialogue\": \"\\\"How are you today?\\\" she asked with a smile. \\\"I'm doing well, thank you,\\\" he replied. \\\"The weather is beautiful, isn't it?\\\" \\\"Yes, perfect for a walk in the park,\\\" she agreed enthusiastically.\",\n",
    "    \"sample_technical\": \"The implementation requires instantiation of the primary data structure followed by iterative processing of the input parameters. Error handling mechanisms must be incorporated to ensure robust operation under various edge case conditions and unexpected input variations.\"\n",
    "}\n",
    "\n",
    "# Add sample texts to corpus\n",
    "for record_name, text_content in sample_texts.items():\n",
    "    corpus.add(\n",
    "        content=text_content,\n",
    "        name=record_name,\n",
    "        is_active=True,\n",
    "        metadata={'type': 'sample', 'category': record_name.split('_')[1]}\n",
    "    )\n",
    "\n",
    "print(f\"‚úì Added {len(sample_texts)} records\")\n",
    "\n",
    "print(f\"\\nüìä Corpus Status:\")\n",
    "print(f\"   - Total records: {corpus.num_docs}\")\n",
    "print(f\"   - Active records: {corpus.num_active_docs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Add From Text Files\n",
    "\n",
    "Run the cell below to add records from files, add the paths to your files in the `file_paths` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these example file paths with your actual files\n",
    "file_paths = [\n",
    "    # \"path/to/your/record1.txt\",\n",
    "    # \"path/to/your/record2.txt\",\n",
    "    # \"path/to/your/record3.txt\",\n",
    "]\n",
    "\n",
    "# Create a loader instance and load the files\n",
    "loader = Loader()\n",
    "loader.load(file_paths)\n",
    "\n",
    "# Load each of the files and create a record\n",
    "for i, doc in enumerate(loader.texts):\n",
    "    record_name = Path(file_paths[i]).stem  # Use filename without extension\n",
    "    corpus.add(\n",
    "        content=doc,\n",
    "        name=record_name,\n",
    "        is_active=True,\n",
    "        metadata={'type': 'sample', 'category': record_name.split('_')[1], 'source_file': file_paths[i]}\n",
    "    )\n",
    "    print(f\"‚úì Added: {record_name}\")\n",
    "\n",
    "print(f\"‚úì Added {len(loader.texts)} records\")\n",
    "\n",
    "print(f\"\\nüìä Corpus Status:\")\n",
    "print(f\"   - Total records: {corpus.num_docs}\")\n",
    "print(f\"   - Active records: {corpus.num_active_docs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Add Processed spaCy Documents\n",
    "\n",
    "In the example below, we will create spaCy `Doc` versions of our sample texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Lexos Tokenizer\n",
    "from lexos.tokenizer import Tokenizer\n",
    "\n",
    "sample_texts = {\n",
    "    \"sample_literature\": \"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.\",\n",
    "    \"sample_academic\": \"The rapid advancement of artificial intelligence has profound implications for various sectors of society. Machine learning algorithms are increasingly being deployed in healthcare, finance, and education, raising important questions about accountability, transparency, and fairness in automated decision-making systems.\",\n",
    "    \"sample_news\": \"Local authorities announced today that the new community center will open next month. The facility will feature a library, gymnasium, and meeting spaces for local organizations. Residents have been eagerly anticipating the opening since construction began two years ago.\",\n",
    "    \"sample_dialogue\": \"\\\"How are you today?\\\" she asked with a smile. \\\"I'm doing well, thank you,\\\" he replied. \\\"The weather is beautiful, isn't it?\\\" \\\"Yes, perfect for a walk in the park,\\\" she agreed enthusiastically.\",\n",
    "    \"sample_technical\": \"The implementation requires instantiation of the primary data structure followed by iterative processing of the input parameters. Error handling mechanisms must be incorporated to ensure robust operation under various edge case conditions and unexpected input variations.\"\n",
    "}\n",
    "\n",
    "# Convert the texts to spaCy Docs\n",
    "tokenizer = Tokenizer(model=\"en_core_web_sm\")\n",
    "names = list(sample_texts.keys())\n",
    "docs = [tokenizer.make_doc(text) for text in sample_texts.values()]\n",
    "sample_docs = dict(zip(names, docs))\n",
    "\n",
    "# Add docs to corpus\n",
    "for record_name, doc in sample_docs.items():\n",
    "    corpus.add(\n",
    "        content=doc,\n",
    "        name=record_name,\n",
    "        is_active=True,\n",
    "        model=\"en_core_web_sm\",\n",
    "        metadata={\"type\": \"sample\", \"category\": record_name.split(\"_\")[1]}\n",
    "    )\n",
    "\n",
    "# Get the number of parsed docs in the corpus\n",
    "num_parsed_docs = sum([1 for r in corpus.records.values() if r.is_parsed])\n",
    "\n",
    "print(f\"‚úì Added {len(sample_docs)} records\")\n",
    "\n",
    "print(f\"\\nüìä Corpus Status:\")\n",
    "print(f\"   - Total records: {corpus.num_docs}\")\n",
    "print(f\"   - Active records: {corpus.num_active_docs}\")\n",
    "print(f\"   - Parsed docs in corpus: {num_parsed_docs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Your Corpus\n",
    "\n",
    "When you add a record to a corpus, it is stored as a dict, which can access with `corpus.records`. The keys are the records' ids and the values are the `Record` objects. Accessing records is often easier when iterating through the corpus itself, which returns just the `Record` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in corpus:\n",
    "    print(f\"- {record.name}: {record.preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove a record, use `remove()`, passing it the `id` or `name` of the record. Be careful when using names; if there are duplicate record names, all records with the name you supply will be deleted.\n",
    "\n",
    "Use the `set()` method to set properties of a record based on its id. For instance `corpus.set(\"3eb16839-ab0d-4f5b-ae85-39561d687a6e\", is_active=False)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Records\n",
    "\n",
    "To find individual records, use the `get()` method. If you get a single result, the method will return a `Record` object. If you get multiple results, it will be a list of `Record` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = corpus.get(name=\"sample_literature\")\n",
    "for record in result:\n",
    "    # print(record.id, record.name)\n",
    "    print(repr(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for records by metadata, use `filter_records()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = corpus.filter_records(category=\"technical\")\n",
    "for record in result:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `filter_records()` has some limitations, especially when filtering multiple categories. For your precise usage, you may have to use a broad search and then narrow down the contents programmatically yourself. For more complex queries, you have the option to use a database. See the separate tutorial on using SQLite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Your Corpus in a Table\n",
    "\n",
    "You can display your corpus as a pandas DataFrame with the `to_df()` method. This method has an `exclude` parameter which takes a list of columns to hide (by default, `[\"content\", \"terms\", \"tokens\"]`). If you wish to exclude metadata fields with the same name as model fields, you can use the prefix \"metadata_\" to avoid conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_df(exclude=[\"content\", \"terms\", \"tokens\", \"preview\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Your Corpus to Disk\n",
    "\n",
    "To save your entire corpus to a zip file, use the `save()` method:\n",
    "\n",
    "```python\n",
    "corpus.save(path=\"path/to/your/zip/file\")\n",
    "```\n",
    "\n",
    "You can load a zipped corpus back into a `Corpus` instance with the `load()` method:\n",
    "\n",
    "```python\n",
    "corpus.load(path=\"path/to/your/zip/file\")\n",
    "```\n",
    "\n",
    "If you supply a `corpus_dir`, the new unzipped corpus files will be saved to that directory; otherwise, the current directory will be used. If your records have a language model, set `cache=True` so that it will only be loaded once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Corpus Statistics\n",
    "\n",
    "You can get a quick list of the term counts in your corpus with the `term_counts()` method. The cell below demonstrates the available keyword parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"10 Most common terms in the corpus:\")\n",
    "print(corpus.term_counts())\n",
    "\n",
    "print()\n",
    "print(\"5 Least common terms in the corpus:\")\n",
    "print(corpus.term_counts(n=5, most_common=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Corpus module allows you to generate a range of more advanced statistics about your data. This can help you\n",
    "\n",
    "- **Understand the quality of your corpus:** Is your corpus large enough for meaningful analysis? Are your documents similar in length, or do you have problematic outliers? Do you have enough vocabulary diversity for reliable results? \n",
    "- **Compare different types of texts:** Are there meaningful differences between my documents groups? Which documents are most similar to or different from each other? Do certain authors/genres/time periods show distinct patterns?\n",
    "- **Examine distinct linguistic patterns:** How rich and diverse in the vocabulary in your corpus? Are there distinctive terms or linguistic features? Are there unusual language patterns worth investigating?\n",
    "-- **Decide how to prepare data for advanced analysis:** Is your data suitable for the analysis techniques you want to use? How shold you handle outliers and unusual documents? What quality thresholds should you set for your analysis?\n",
    "\n",
    "A best practice is to begin by assessing the quality of your corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Corpus Quality\n",
    "\n",
    "In the cell below, we use the `get_stats()` method to generate a `CorpusStats` instance. We then print various properties of the `CorpusStats` class, along with statistical properties of the `Corpus` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive corpus statistics\n",
    "print(\"üìä BASIC CORPUS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get statistics (this may take a moment for large corpora)\n",
    "stats = corpus.get_stats(active_only=True)\n",
    "\n",
    "print(f\"‚úì Analysis complete for {len(stats.docs)} records\")\n",
    "print(f\"‚úì Working with {len(stats.dtm.sorted_terms_list)} unique terms\")\n",
    "\n",
    "# === CORPUS SIZE AND SCOPE ===\n",
    "print(f\"\\nüìà CORPUS SIZE AND SCOPE\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"üìö Total records in your corpus: {corpus.num_docs}\")\n",
    "print(f\"üìù Active records being analyzed: {corpus.num_active_docs}\")\n",
    "print(f\"üî§ Total unique words/terms: {corpus.num_terms}\")\n",
    "print(f\"üìä Total word tokens: {corpus.num_tokens}\")\n",
    "\n",
    "# === BASIC LENGTH STATISTICS ===\n",
    "print(f\"\\nüìè RECORD LENGTH OVERVIEW\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"üìä Average record length: {stats.mean:.0f} words\")\n",
    "print(f\"üìâ Shortest record: {stats.doc_stats_df['total_tokens'].min()} words\")\n",
    "print(f\"üìà Longest record: {stats.doc_stats_df['total_tokens'].max()} words\")\n",
    "print(f\"üìê Length variation: {stats.standard_deviation:.0f} words (standard deviation)\")\n",
    "\n",
    "# Interpret the length variation\n",
    "cv = stats.standard_deviation / stats.mean if stats.mean > 0 else 0\n",
    "if cv < 0.15:\n",
    "    length_interpretation = \"Very similar lengths - good for comparison studies\"\n",
    "elif cv < 0.3:\n",
    "    length_interpretation = \"Moderately similar lengths - typical for most research\"\n",
    "else:\n",
    "    length_interpretation = \"Highly variable lengths - check for outliers\"\n",
    "\n",
    "print(f\"üí° Interpretation: {length_interpretation}\")\n",
    "\n",
    "# === CORPUS QUALITY ASSESSMENT ===\n",
    "print(f\"\\nüéØ CORPUS QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "quality_metrics = stats.corpus_quality_metrics\n",
    "\n",
    "# Size adequacy\n",
    "size_adequacy = quality_metrics['corpus_size_metrics']['size_adequacy']\n",
    "size_icon = \"‚úÖ\" if size_adequacy in ['adequate', 'large'] else \"‚ö†Ô∏è\" if size_adequacy == 'small' else \"‚ùå\"\n",
    "print(f\"{size_icon} Corpus size: {size_adequacy.upper()}\")\n",
    "\n",
    "if size_adequacy == 'very_small':\n",
    "    print(f\"   üìù Recommendation: Add more records for reliable analysis\")\n",
    "    print(f\"   üéØ Minimum suggested: {quality_metrics['corpus_size_metrics']['recommended_min_docs']} records\")\n",
    "elif size_adequacy == 'small':\n",
    "    print(f\"   üìù Note: Results will be more reliable with additional records\")\n",
    "else:\n",
    "    print(f\"   üìù Great! Your corpus size is suitable for analysis\")\n",
    "\n",
    "# Length balance\n",
    "length_balance = quality_metrics['document_length_balance']['classification']\n",
    "balance_icon = \"‚úÖ\" if length_balance == 'balanced' else \"‚ö†Ô∏è\" if length_balance == 'slightly_imbalanced' else \"‚ùå\"\n",
    "print(f\"{balance_icon} Record length balance: {length_balance.upper()}\")\n",
    "\n",
    "if length_balance == 'highly_imbalanced':\n",
    "    print(f\"   üìù Recommendation: Check for very long/short records that might skew results\")\n",
    "elif length_balance == 'slightly_imbalanced':\n",
    "    print(f\"   üìù Note: Some length variation is normal and usually fine\")\n",
    "else:\n",
    "    print(f\"   üìù Great! Your records have consistent lengths\")\n",
    "\n",
    "# Vocabulary richness\n",
    "vocab_richness = quality_metrics['vocabulary_richness']['sampling_adequacy']\n",
    "vocab_icon = \"‚úÖ\" if vocab_richness == 'sufficient' else \"‚ö†Ô∏è\" if vocab_richness == 'marginal' else \"‚ùå\"\n",
    "print(f\"{vocab_icon} Vocabulary diversity: {vocab_richness.upper()}\")\n",
    "\n",
    "if vocab_richness == 'insufficient':\n",
    "    print(f\"   üìù Recommendation: Consider adding more diverse texts\")\n",
    "elif vocab_richness == 'marginal':\n",
    "    print(f\"   üìù Note: Vocabulary diversity is adequate but could be improved\")\n",
    "else:\n",
    "    print(f\"   üìù Great! Your corpus has rich vocabulary diversity\")\n",
    "\n",
    "print(f\"\\nüí° Overall Assessment:\")\n",
    "if all(metric in ['adequate', 'large', 'balanced', 'sufficient']\n",
    "       for metric in [size_adequacy, length_balance, vocab_richness]):\n",
    "    print(f\"üéâ Excellent! Your corpus is well-suited for text analysis.\")\n",
    "else:\n",
    "    print(f\"üìù Your corpus is usable, but consider the recommendations above for optimal results.\")\n",
    "\n",
    "# === OUTLIER DETECTION (SIMPLIFIED) ===\n",
    "print(f\"\\nüîç UNUSUAL RECORDS (OUTLIER DETECTION)\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "outliers = stats.iqr_outliers\n",
    "if outliers:\n",
    "    print(f\"‚ö†Ô∏è Found {len(outliers)} records with unusual lengths:\")\n",
    "    for record_id, record_name in outliers[:5]:  # Show first 5 outliers\n",
    "        record = corpus.get(id=record_id)\n",
    "        length = record.num_tokens() if record.is_parsed else len(record.content.split())\n",
    "        print(f\"   üìÑ {record_name}: {length} words\")\n",
    "\n",
    "    if len(outliers) > 5:\n",
    "        print(f\"   ... and {len(outliers) - 5} more\")\n",
    "\n",
    "    print(f\"\\nüí° What this means:\")\n",
    "    print(f\"   ‚Ä¢ These records are much longer or shorter than typical\")\n",
    "    print(f\"   ‚Ä¢ This is often normal (prefaces, abstracts, etc.)\")\n",
    "    print(f\"   ‚Ä¢ Consider if these should be included in your analysis\")\n",
    "else:\n",
    "    print(f\"‚úÖ No unusual record lengths detected\")\n",
    "    print(f\"üí° All records have similar lengths - great for comparative analysis!\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"üéØ NEXT STEPS:\")\n",
    "print(f\"‚Ä¢ If all assessments look good ‚Üí proceed to advanced analysis\")\n",
    "print(f\"‚Ä¢ If you see warnings ‚Üí consider adding more/different records\")\n",
    "print(f\"‚Ä¢ If you have outliers ‚Üí decide whether to include or exclude them\")\n",
    "print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics for Comparative Text Analysis \n",
    "\n",
    "*Perfect for: Literary studies, genre analysis, authorship studies, comparing time periods*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìö COMPARATIVE TEXT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Perfect for: Comparing authors, genres, time periods, or any text groups\")\n",
    "print()\n",
    "\n",
    "# === ANALYZING TEXT GROUPS ===\n",
    "print(\"üîç ANALYZING YOUR TEXT GROUPS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Check if we have metadata categories for comparison\n",
    "metadata_categories = {}\n",
    "for record in corpus.records.values():\n",
    "    if record.is_active and record.meta.get('category'):\n",
    "        category = record.meta.get('category', 'unknown')\n",
    "        if category not in metadata_categories:\n",
    "            metadata_categories[category] = {'records': [], 'lengths': []}\n",
    "\n",
    "        metadata_categories[category]['records'].append(record.name)\n",
    "        if record.is_parsed:\n",
    "            metadata_categories[category]['lengths'].append(record.num_tokens())\n",
    "        else:\n",
    "            metadata_categories[category]['lengths'].append(len(record.content.split()))\n",
    "\n",
    "if len(metadata_categories) > 1:\n",
    "    print(f\"üìä Found {len(metadata_categories)} text groups in your corpus:\")\n",
    "    for category, data in metadata_categories.items():\n",
    "        avg_length = sum(data['lengths']) / len(data['lengths'])\n",
    "        print(f\"   üìñ {category.title()}: {len(data['records'])} records, avg {avg_length:.0f} words\")\n",
    "\n",
    "    # === STATISTICAL COMPARISON ===\n",
    "    print(f\"\\nüßÆ STATISTICAL COMPARISON BETWEEN GROUPS\")\n",
    "    print(\"=\" * 45)\n",
    "\n",
    "    # Get two largest groups for comparison\n",
    "    sorted_groups = sorted(metadata_categories.items(), key=lambda x: len(x[1]['records']), reverse=True)\n",
    "    if len(sorted_groups) >= 2:\n",
    "        group1_name, group1_data = sorted_groups[0]\n",
    "        group2_name, group2_data = sorted_groups[1]\n",
    "\n",
    "        print(f\"üÜö Comparing: {group1_name.title()} vs {group2_name.title()}\")\n",
    "\n",
    "        try:\n",
    "            comparison = stats.compare_groups(\n",
    "                group1_labels=group1_data['records'],\n",
    "                group2_labels=group2_data['records'],\n",
    "                metric=\"total_tokens\",\n",
    "                test_type=\"mann_whitney\"\n",
    "            )\n",
    "\n",
    "            # Explain the comparison in accessible terms\n",
    "            print(f\"\\nüìä Statistical Results:\")\n",
    "            print(f\"   {group1_name.title()} average: {comparison['group1_mean']:.0f} words\")\n",
    "            print(f\"   {group2_name.title()} average: {comparison['group2_mean']:.0f} words\")\n",
    "\n",
    "            # Interpret the p-value\n",
    "            if comparison['p_value'] < 0.001:\n",
    "                significance = \"Very strong evidence\"\n",
    "            elif comparison['p_value'] < 0.01:\n",
    "                significance = \"Strong evidence\"\n",
    "            elif comparison['p_value'] < 0.05:\n",
    "                significance = \"Moderate evidence\"\n",
    "            else:\n",
    "                significance = \"No clear evidence\"\n",
    "\n",
    "            print(f\"\\nüí° What this means:\")\n",
    "            print(f\"   ‚Ä¢ {significance} of a real difference between groups\")\n",
    "            if comparison['is_significant']:\n",
    "                print(f\"   ‚Ä¢ The length difference is statistically meaningful\")\n",
    "                print(f\"   ‚Ä¢ Effect size: {comparison['effect_size_interpretation']} difference\")\n",
    "            else:\n",
    "                print(f\"   ‚Ä¢ The groups are similar in length\")\n",
    "                print(f\"   ‚Ä¢ Any difference could be due to chance\")\n",
    "\n",
    "            print(f\"\\nüìà Research Implications:\")\n",
    "            if comparison['is_significant']:\n",
    "                print(f\"   ‚úÖ Groups show distinct patterns - good for comparative analysis\")\n",
    "                print(f\"   üî¨ Consider investigating what causes this difference\")\n",
    "            else:\n",
    "                print(f\"   ‚úÖ Groups are comparable - good for controlled comparisons\")\n",
    "                print(f\"   üî¨ Focus on content/style rather than length differences\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Could not compare groups: {e}\")\n",
    "\n",
    "    # === OUTLIER ANALYSIS FOR GROUPS ===\n",
    "    print(f\"\\nüéØ OUTLIERS WITHIN EACH GROUP\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    outliers = stats.iqr_outliers\n",
    "    if outliers:\n",
    "        print(f\"Records that don't fit typical patterns:\")\n",
    "\n",
    "        # Group outliers by category\n",
    "        outliers_by_group = {}\n",
    "        for record_id, record_name in outliers:\n",
    "            record = corpus.get(id=record_id)\n",
    "            group = record.meta.get('category', 'unknown')\n",
    "            if group not in outliers_by_group:\n",
    "                outliers_by_group[group] = []\n",
    "            outliers_by_group[group].append(record_name)\n",
    "\n",
    "        for group, group_outliers in outliers_by_group.items():\n",
    "            print(f\"   üìñ {group.title()}: {', '.join(group_outliers)}\")\n",
    "\n",
    "        print(f\"\\nüí° Research Value of Outliers:\")\n",
    "        print(f\"   ‚Ä¢ May represent unique styles or content\")\n",
    "        print(f\"   ‚Ä¢ Could indicate errors in categorization\")\n",
    "        print(f\"   ‚Ä¢ Might be your most interesting findings!\")\n",
    "    else:\n",
    "        print(f\"‚úÖ No outliers found - all texts fit their group patterns well\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùì No text groups found in your metadata.\")\n",
    "    print(f\"üìù To enable group comparison:\")\n",
    "    print(f\"   ‚Ä¢ Add metadata categories like 'genre', 'author', 'period'\")\n",
    "    print(f\"   ‚Ä¢ See the metadata section above for examples\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"üéØ NEXT STEPS FOR COMPARATIVE ANALYSIS:\")\n",
    "print(f\"‚Ä¢ Use clustering tools to find hidden similarities\")\n",
    "print(f\"‚Ä¢ Apply topic modeling to discover thematic differences\")\n",
    "print(f\"‚Ä¢ Try stylometric analysis for authorship studies\")\n",
    "print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üó£Ô∏è Statistics for Linguistic and Vocabulary Analysis\n",
    "\n",
    "*Perfect for: Language studies, vocabulary complexity, linguistic patterns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üó£Ô∏è LINGUISTIC AND VOCABULARY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Perfect for: Language complexity, vocabulary richness, linguistic patterns\")\n",
    "print()\n",
    "\n",
    "# === VOCABULARY DIVERSITY ANALYSIS ===\n",
    "print(\"üìö VOCABULARY DIVERSITY AND RICHNESS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "diversity_stats = stats.text_diversity_stats\n",
    "\n",
    "print(f\"üìä Vocabulary Richness Metrics:\")\n",
    "print(f\"   üéØ Type-Token Ratio (TTR): {diversity_stats['mean_ttr']:.3f}\")\n",
    "print(f\"   üìà Corpus-wide TTR: {diversity_stats['corpus_ttr']:.3f}\")\n",
    "print(f\"   üÜï Rare words ratio: {diversity_stats['mean_hapax_ratio']:.3f}\")\n",
    "\n",
    "print(f\"\\nüí° What these numbers mean:\")\n",
    "\n",
    "# Interpret TTR\n",
    "ttr = diversity_stats['mean_ttr']\n",
    "if ttr > 0.7:\n",
    "    ttr_interpretation = \"Very high vocabulary diversity\"\n",
    "    ttr_meaning = \"Texts use many different words - sophisticated vocabulary\"\n",
    "elif ttr > 0.5:\n",
    "    ttr_interpretation = \"Good vocabulary diversity\"\n",
    "    ttr_meaning = \"Balanced use of vocabulary - typical for quality writing\"\n",
    "elif ttr > 0.3:\n",
    "    ttr_interpretation = \"Moderate vocabulary diversity\"\n",
    "    ttr_meaning = \"Some repetition but still varied vocabulary\"\n",
    "else:\n",
    "    ttr_interpretation = \"Lower vocabulary diversity\"\n",
    "    ttr_meaning = \"More repetitive language - may indicate specialized/technical content\"\n",
    "\n",
    "print(f\"   üìù TTR Assessment: {ttr_interpretation}\")\n",
    "print(f\"      {ttr_meaning}\")\n",
    "\n",
    "# Interpret hapax ratio\n",
    "hapax_ratio = diversity_stats['mean_hapax_ratio']\n",
    "if hapax_ratio > 0.6:\n",
    "    hapax_interpretation = \"High use of unique words\"\n",
    "    hapax_meaning = \"Many words appear only once - rich, varied vocabulary\"\n",
    "elif hapax_ratio > 0.4:\n",
    "    hapax_interpretation = \"Moderate use of unique words\"\n",
    "    hapax_meaning = \"Balanced vocabulary with good variety\"\n",
    "else:\n",
    "    hapax_interpretation = \"Lower use of unique words\"\n",
    "    hapax_meaning = \"More repetitive vocabulary - may be formulaic or specialized\"\n",
    "\n",
    "print(f\"   üìù Rare Words Assessment: {hapax_interpretation}\")\n",
    "print(f\"      {hapax_meaning}\")\n",
    "\n",
    "# === LINGUISTIC PATTERN ANALYSIS ===\n",
    "print(f\"\\nüîç LINGUISTIC PATTERN ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Zipf's Law Analysis\n",
    "zipf_analysis = stats.zipf_analysis\n",
    "print(f\"üìà Language Pattern Analysis (Zipf's Law):\")\n",
    "\n",
    "if zipf_analysis['follows_zipf']:\n",
    "    print(f\"   ‚úÖ Your texts follow expected language patterns\")\n",
    "    print(f\"   üìù This suggests natural, well-formed language\")\n",
    "    print(f\"   üéØ Good fit score: {zipf_analysis['zipf_goodness_of_fit']}\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Your texts show unusual language patterns\")\n",
    "    print(f\"   üìù This might indicate:\")\n",
    "    print(f\"      ‚Ä¢ Highly technical or specialized vocabulary\")\n",
    "    print(f\"      ‚Ä¢ Mixed languages or corrupted text\")\n",
    "    print(f\"      ‚Ä¢ Very small corpus size\")\n",
    "    print(f\"   üéØ Fit score: {zipf_analysis['zipf_goodness_of_fit']}\")\n",
    "\n",
    "print(f\"   üìä Technical details: R¬≤ = {zipf_analysis['r_squared']:.3f}\")\n",
    "\n",
    "# Advanced diversity metrics\n",
    "advanced_diversity = stats.advanced_lexical_diversity\n",
    "print(f\"\\nüìä Advanced Vocabulary Metrics:\")\n",
    "print(f\"   üîÑ CTTR (Corrected TTR): {advanced_diversity['mean_cttr']:.2f}\")\n",
    "print(f\"   üìè RTTR (Root TTR): {advanced_diversity['mean_rttr']:.2f}\")\n",
    "print(f\"   üìà Log TTR: {advanced_diversity['mean_log_ttr']:.3f}\")\n",
    "\n",
    "print(f\"\\nüí° Advanced Metrics Interpretation:\")\n",
    "cttr = advanced_diversity['mean_cttr']\n",
    "if cttr > 5:\n",
    "    print(f\"   ‚úÖ Very high vocabulary sophistication\")\n",
    "elif cttr > 3:\n",
    "    print(f\"   ‚úÖ Good vocabulary sophistication\")\n",
    "elif cttr > 2:\n",
    "    print(f\"   üìù Moderate vocabulary sophistication\")\n",
    "else:\n",
    "    print(f\"   üìù Lower vocabulary sophistication\")\n",
    "\n",
    "# === VOCABULARY DISTRIBUTION ===\n",
    "print(f\"\\nüìã VOCABULARY DISTRIBUTION PATTERNS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"üìä Most Common Words in Your Corpus:\")\n",
    "try:\n",
    "    top_terms = corpus.term_counts(n=10, most_common=True)\n",
    "    for i, (term, count) in enumerate(top_terms, 1):\n",
    "        percentage = (count / corpus.num_tokens * 100) if corpus.num_tokens > 0 else 0\n",
    "        print(f\"   {i:2d}. '{term}': {count} times ({percentage:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nüí° Vocabulary Insights:\")\n",
    "    # Check if top words are function words (common pattern)\n",
    "    function_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'can', 'shall', 'must'}\n",
    "    top_words = [term.lower() for term, _ in top_terms[:5]]\n",
    "    function_word_count = sum(1 for word in top_words if word in function_words)\n",
    "\n",
    "    if function_word_count >= 3:\n",
    "        print(f\"   ‚úÖ Natural language patterns - function words dominate\")\n",
    "        print(f\"   üìù This indicates well-formed, natural text\")\n",
    "    else:\n",
    "        print(f\"   ü§î Unusual word frequency patterns detected\")\n",
    "        print(f\"   üìù May indicate technical content or data processing needed\")\n",
    "\n",
    "except:\n",
    "    print(f\"   (Could not analyze term frequencies - may need processed records)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"üéØ NEXT STEPS FOR LINGUISTIC ANALYSIS:\")\n",
    "print(f\"‚Ä¢ Use n-gram analysis to study phrase patterns\")\n",
    "print(f\"‚Ä¢ Apply part-of-speech analysis for grammatical patterns\")\n",
    "print(f\"‚Ä¢ Try collocation analysis for word association patterns\")\n",
    "print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics for Advanced Analysis Preparation\n",
    "\n",
    "*Perfect for: Machine learning, topic modeling, clustering, classification projects*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä ADVANCED ANALYSIS PREPARATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Perfect for: Preparing data for machine learning, topic modeling, clustering\")\n",
    "print()\n",
    "\n",
    "# === DATA QUALITY ASSESSMENT FOR ML ===\n",
    "print(\"üéØ DATA QUALITY FOR ADVANCED ANALYSIS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "quality_metrics = stats.corpus_quality_metrics\n",
    "\n",
    "print(f\"üìä Suitability Assessment:\")\n",
    "\n",
    "# Sample size adequacy\n",
    "size_metrics = quality_metrics['corpus_size_metrics']\n",
    "size_adequacy = size_metrics['size_adequacy']\n",
    "\n",
    "if size_adequacy == 'very_small':\n",
    "    size_recommendation = \"‚ùå Too small for reliable ML - add more records\"\n",
    "    ml_ready = False\n",
    "elif size_adequacy == 'small':\n",
    "    size_recommendation = \"‚ö†Ô∏è Marginal for ML - results may be unstable\"\n",
    "    ml_ready = False\n",
    "elif size_adequacy == 'adequate':\n",
    "    size_recommendation = \"‚úÖ Good size for most analysis techniques\"\n",
    "    ml_ready = True\n",
    "else:  # large\n",
    "    size_recommendation = \"‚úÖ Excellent size for advanced analysis\"\n",
    "    ml_ready = True\n",
    "\n",
    "print(f\"   üìà Corpus size: {size_recommendation}\")\n",
    "\n",
    "# Vocabulary richness for ML\n",
    "vocab_richness = quality_metrics['vocabulary_richness']\n",
    "sampling_adequacy = vocab_richness['sampling_adequacy']\n",
    "\n",
    "if sampling_adequacy == 'insufficient':\n",
    "    vocab_recommendation = \"‚ùå Insufficient vocabulary diversity for ML\"\n",
    "    vocab_ready = False\n",
    "elif sampling_adequacy == 'marginal':\n",
    "    vocab_recommendation = \"‚ö†Ô∏è Limited vocabulary diversity - may affect results\"\n",
    "    vocab_ready = False\n",
    "else:  # sufficient\n",
    "    vocab_recommendation = \"‚úÖ Good vocabulary diversity for analysis\"\n",
    "    vocab_ready = True\n",
    "\n",
    "print(f\"   üìö Vocabulary diversity: {vocab_recommendation}\")\n",
    "\n",
    "# Distribution analysis for statistical assumptions\n",
    "print(f\"\\nüìà STATISTICAL DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "dist_stats = stats.distribution_stats\n",
    "\n",
    "print(f\"üìä Data Distribution Properties:\")\n",
    "print(f\"   üìê Symmetry (skewness): {dist_stats['skewness']:.3f}\")\n",
    "\n",
    "if abs(dist_stats['skewness']) < 0.5:\n",
    "    skewness_interp = \"Symmetric distribution - good for most methods\"\n",
    "elif abs(dist_stats['skewness']) < 1.0:\n",
    "    skewness_interp = \"Slightly skewed - usually fine for analysis\"\n",
    "else:\n",
    "    skewness_interp = \"Highly skewed - may need data transformation\"\n",
    "\n",
    "print(f\"      üí° {skewness_interp}\")\n",
    "\n",
    "print(f\"   üìä Normality test: {'Normally distributed' if dist_stats['is_normal'] else 'Non-normal distribution'}\")\n",
    "if not dist_stats['is_normal']:\n",
    "    print(f\"      üí° Non-parametric methods recommended\")\n",
    "else:\n",
    "    print(f\"      üí° Both parametric and non-parametric methods suitable\")\n",
    "\n",
    "print(f\"   üìè Variability: {dist_stats['coefficient_of_variation']:.3f}\")\n",
    "if dist_stats['coefficient_of_variation'] < 0.2:\n",
    "    var_interp = \"Low variability - consistent record lengths\"\n",
    "elif dist_stats['coefficient_of_variation'] < 0.5:\n",
    "    var_interp = \"Moderate variability - typical for text data\"\n",
    "else:\n",
    "    var_interp = \"High variability - consider length normalization\"\n",
    "\n",
    "print(f\"      üí° {var_interp}\")\n",
    "\n",
    "# === PREPROCESSING RECOMMENDATIONS ===\n",
    "print(f\"\\nüîß PREPROCESSING RECOMMENDATIONS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "print(f\"üìã Based on your corpus analysis:\")\n",
    "\n",
    "outliers = stats.iqr_outliers\n",
    "if outliers:\n",
    "    print(f\"   ‚ö†Ô∏è Outlier handling: {len(outliers)} unusual records detected\")\n",
    "    print(f\"      ‚Ä¢ Consider removing or treating outliers separately\")\n",
    "    print(f\"      ‚Ä¢ May improve model performance and interpretability\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Outlier handling: No problematic outliers detected\")\n",
    "\n",
    "if dist_stats['coefficient_of_variation'] > 0.5:\n",
    "    print(f\"   üìè Length normalization: Recommended due to high variability\")\n",
    "    print(f\"      ‚Ä¢ Consider document-length normalization\")\n",
    "    print(f\"      ‚Ä¢ May improve clustering and classification results\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Length normalization: Not required - consistent lengths\")\n",
    "\n",
    "if vocab_richness['vocabulary_saturation'] < 1.5:\n",
    "    print(f\"   üìö Vocabulary filtering: Consider removing very rare words\")\n",
    "    print(f\"      ‚Ä¢ Set minimum frequency thresholds\")\n",
    "    print(f\"      ‚Ä¢ May improve model stability\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Vocabulary filtering: Good vocabulary coverage\")\n",
    "\n",
    "# === ML READINESS ASSESSMENT ===\n",
    "print(f\"\\nü§ñ MACHINE LEARNING READINESS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "readiness_score = 0\n",
    "max_score = 4\n",
    "\n",
    "if ml_ready:\n",
    "    readiness_score += 1\n",
    "    print(f\"   ‚úÖ Sample size: Adequate\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Sample size: Insufficient\")\n",
    "\n",
    "if vocab_ready:\n",
    "    readiness_score += 1\n",
    "    print(f\"   ‚úÖ Vocabulary diversity: Good\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Vocabulary diversity: Limited\")\n",
    "\n",
    "if len(outliers) <= len(stats.docs) * 0.1:  # Less than 10% outliers\n",
    "    readiness_score += 1\n",
    "    print(f\"   ‚úÖ Data quality: Good (few outliers)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Data quality: Consider outlier treatment\")\n",
    "\n",
    "if dist_stats['coefficient_of_variation'] < 0.8:  # Reasonable variability\n",
    "    readiness_score += 1\n",
    "    print(f\"   ‚úÖ Consistency: Good variability levels\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Consistency: High variability detected\")\n",
    "\n",
    "print(f\"\\nüéØ Overall ML Readiness: {readiness_score}/{max_score}\")\n",
    "\n",
    "if readiness_score >= 3:\n",
    "    print(f\"   üéâ Your corpus is ready for advanced analysis!\")\n",
    "    print(f\"   üöÄ Recommended next steps:\")\n",
    "    print(f\"      ‚Ä¢ Topic modeling with LDA or similar\")\n",
    "    print(f\"      ‚Ä¢ Document clustering analysis\")\n",
    "    print(f\"      ‚Ä¢ Classification experiments\")\n",
    "elif readiness_score >= 2:\n",
    "    print(f\"   üìù Your corpus needs minor improvements\")\n",
    "    print(f\"   üîß Address the issues above, then proceed\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Your corpus needs significant preparation\")\n",
    "    print(f\"   üìö Consider adding more diverse records\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"üéØ NEXT STEPS FOR ADVANCED ANALYSIS:\")\n",
    "print(f\"‚Ä¢ Export your corpus for external ML tools\")\n",
    "print(f\"‚Ä¢ Use Lexos clustering and topic modeling modules\")\n",
    "print(f\"‚Ä¢ Set up document classification experiments\")\n",
    "print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and Reporting\n",
    "\n",
    "When you call `Corpus.get_stats()` to produce a `CorpusStats` instance, that instance has a `doc_stats_df` property. This returns a pandas DataFrame with all the generated statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.doc_stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data extracted from this table can be fed into a variety of plotting tools to generate graphs. The following examples use the Python `matplotlib` package, but they are meant only as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä CREATING VISUALIZATIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Set up matplotlib for better plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Create a visualization of document statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle(f'Corpus Analysis: {corpus.name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Document length distribution\n",
    "doc_lengths = stats.doc_stats_df['total_tokens']\n",
    "\n",
    "axes[0, 0].hist(doc_lengths, bins=min(10, len(doc_lengths)), alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].axvline(stats.mean, color='red', linestyle='--', label=f'Mean: {stats.mean:.1f}')\n",
    "axes[0, 0].set_title('Document Length Distribution')\n",
    "axes[0, 0].set_xlabel('Number of Tokens')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Vocabulary density distribution\n",
    "vocab_density = stats.doc_stats_df['vocabulary_density']\n",
    "axes[0, 1].hist(vocab_density, bins=min(10, len(vocab_density)), alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].axvline(vocab_density.mean(), color='red', linestyle='--', label=f'Mean: {vocab_density.mean():.1f}%')\n",
    "axes[0, 1].set_title('Vocabulary Density Distribution')\n",
    "axes[0, 1].set_xlabel('Vocabulary Density (%)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Document comparison (length vs vocabulary)\n",
    "doc_stats_plot = stats.doc_stats_df\n",
    "scatter = axes[1, 0].scatter(doc_stats_plot['total_tokens'], doc_stats_plot['vocabulary_density'],\n",
    "                           alpha=0.7, s=60, c='purple')\n",
    "axes[1, 0].set_title('Document Length vs Vocabulary Density')\n",
    "axes[1, 0].set_xlabel('Total Tokens')\n",
    "axes[1, 0].set_ylabel('Vocabulary Density (%)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add document names as tooltips (if not too many)\n",
    "if len(doc_stats_plot) <= 20:\n",
    "    for i, (idx, row) in enumerate(doc_stats_plot.iterrows()):\n",
    "        axes[1, 0].annotate(idx, (row['total_tokens'], row['vocabulary_density']),\n",
    "                          xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.7)\n",
    "\n",
    "# 4. Outlier identification plot\n",
    "doc_lengths_list = doc_stats_plot['total_tokens'].tolist()\n",
    "colors = ['red' if any(idx in [o[1] for o in outliers] for o in [('', idx)])\n",
    "          else 'blue' for idx in doc_stats_plot.index]\n",
    "\n",
    "axes[1, 1].scatter(range(len(doc_lengths_list)), doc_lengths_list, c=colors, alpha=0.7, s=60)\n",
    "axes[1, 1].axhline(stats.iqr_bounds[0], color='orange', linestyle='--', alpha=0.7, label='IQR Lower Bound')\n",
    "axes[1, 1].axhline(stats.iqr_bounds[1], color='orange', linestyle='--', alpha=0.7, label='IQR Upper Bound')\n",
    "axes[1, 1].axhline(stats.mean, color='green', linestyle='-', alpha=0.7, label='Mean')\n",
    "axes[1, 1].set_title('Outlier Detection (Red = Outliers)')\n",
    "axes[1, 1].set_xlabel('Document Index')\n",
    "axes[1, 1].set_ylabel('Token Count')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization complete!\")\n",
    "print(\"\\nüí° Interpretation Guide:\")\n",
    "print(\"   üìä Top Left: Shows how document lengths are distributed\")\n",
    "print(\"   üìà Top Right: Shows vocabulary richness patterns\")\n",
    "print(\"   üîç Bottom Left: Reveals relationships between length and vocabulary\")\n",
    "print(\"   üéØ Bottom Right: Identifies unusual documents (outliers in red)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-Module Integration with Other Modules\n",
    "\n",
    "The `export_statistical_fingerprint()` method returns a dictionary with basic statistics about your corpus, which can be useful for passing this information to other Lexos modules or external tools. Since the state of a corpus can change, each time you generate the dictionary, it is assigned a unique ID corresponding to the state of the corpus at the time of export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export statistical fingerprint for other modules\n",
    "fingerprint = corpus.export_statistical_fingerprint()\n",
    "\n",
    "print(\"üìä Statistical Fingerprint Generated:\")\n",
    "print(f\"   Corpus: {fingerprint['corpus_metadata']['name']}\")\n",
    "print(f\"   Documents: {fingerprint['corpus_metadata']['num_docs']}\")\n",
    "print(f\"   Active docs: {fingerprint['corpus_metadata']['num_active_docs']}\")\n",
    "print(f\"   Total tokens: {fingerprint['corpus_metadata']['num_tokens']}\")\n",
    "print(f\"   Fingerprint ID: {fingerprint['corpus_metadata']['corpus_fingerprint']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the rich statistics you can generate with the `Corpus` class, you are not limited\n",
    "to these statistics. You may have performed your own analysis using another Lexos module or some other means. The `Corpus` class provides a number methods for managing statistics from external sources. The `import_analysis_results()` is used to ingest a dictionary of arbitrary statistical data. The data can be accessed by calling `get_analysis_results()`. The cell below demonstrates the the use of these methods using some sample statistics you might have generated with another module.\n",
    "\n",
    "Note that you cannot import analysis results more than once. If you need to do so, use the `overwrite=True` to replace the current contents. In the cell below, this parameter is set in case you run the cell more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîó INTER-MODULE INTEGRATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\\nüß™ Simulating Analysis Module Integration:\")\n",
    "\n",
    "# Simulate how other modules would store results\n",
    "# Example 1: Classification results\n",
    "classification_results = {\n",
    "    'algorithm': 'simulated_classifier',\n",
    "    'accuracy': 0.85,\n",
    "    'predictions': {\n",
    "        doc_name: {\n",
    "            'predicted_class': 'positive' if 'literature' in doc_name or 'academic' in doc_name else 'neutral',\n",
    "            'confidence': 0.75 + (hash(doc_name) % 20) / 100  # Simulated confidence\n",
    "        }\n",
    "        for doc_name in corpus.names.keys()\n",
    "    },\n",
    "    'model_parameters': {\n",
    "        'features': 'bag_of_words',\n",
    "        'training_size': 1000\n",
    "    }\n",
    "}\n",
    "\n",
    "# Store classification results in corpus\n",
    "corpus.import_analysis_results(\n",
    "    module_name='text_classification',\n",
    "    results_data=classification_results,\n",
    "    version='1.0.0',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Stored classification results\")\n",
    "\n",
    "# Example 2: Topic modeling results\n",
    "topic_modeling_results = {\n",
    "    'algorithm': 'LDA',\n",
    "    'n_topics': 3,\n",
    "    'coherence_score': 0.62,\n",
    "    'topics': {\n",
    "        'topic_0': ['academic', 'research', 'analysis', 'data'],\n",
    "        'topic_1': ['literature', 'story', 'character', 'narrative'],\n",
    "        'topic_2': ['news', 'community', 'local', 'center']\n",
    "    },\n",
    "    'document_topics': {\n",
    "        doc_name: {\n",
    "            'dominant_topic': hash(doc_name) % 3,\n",
    "            'topic_distribution': [\n",
    "                0.3 + (hash(doc_name + 'a') % 40) / 100,\n",
    "                0.3 + (hash(doc_name + 'b') % 40) / 100,\n",
    "                0.3 + (hash(doc_name + 'c') % 40) / 100\n",
    "            ]\n",
    "        }\n",
    "        for doc_name in corpus.names.keys()\n",
    "    }\n",
    "}\n",
    "\n",
    "corpus.import_analysis_results(\n",
    "    module_name='topic_modeling',\n",
    "    results_data=topic_modeling_results,\n",
    "    version='2.1.0',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Stored topic modeling results\")\n",
    "\n",
    "# Show stored results\n",
    "print(f\"\\nüìã Analysis Results Summary:\")\n",
    "all_results = corpus.get_analysis_results()\n",
    "for module_name, data in all_results.items():\n",
    "    print(f\"   üìä {module_name}:\")\n",
    "    print(f\"      Version: {data['version']}\")\n",
    "    print(f\"      Timestamp: {data['timestamp']}\")\n",
    "    print(f\"      Corpus state: {len(data['corpus_state'])} tracked properties\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the corpus can change, it is important to check whether the analysis results are still valid for the current state of the corpus. For this, use `validate_analysis_compatibility()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüîç Corpus State Validation:\")\n",
    "# Check if analysis results are still valid\n",
    "for module_name in all_results.keys():\n",
    "    compatibility = corpus.validate_analysis_compatibility(module_name)\n",
    "    status = \"‚úì Valid\" if compatibility['compatible'] else \"‚ö†Ô∏è Outdated\"\n",
    "    print(f\"   {module_name}: {status}\")\n",
    "    if not compatibility['compatible']:\n",
    "        print(f\"      Reason: {compatibility['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Reports\n",
    "\n",
    "In the cells above, you generated a variety of reports about your corpus by hand-coding the outputs in the notebook cell. Whilst this gives you a lot of flexibility to change the output, it would be much simpler to generate these reports with a single function call. For this purpose, the Corpus module has a `create_corpus_analysis_report()`.  This function will generate comprehensive reports about the contents of your corpus in a single line of code. By default, it will return the output in Markdown format. However, if you supply and `output_dir`, it will create a directory (if it does not exist) and save the output there, along with CSV and JSON files containing your corpus statistics. If you set `html=True` the report output will be saved in HTML format for viewing in a web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.corpus.corpus_analysis_report import create_corpus_analysis_report\n",
    "\n",
    "report = create_corpus_analysis_report(corpus)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
