{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DTM` Tutorial\n",
    "   \n",
    "This notebook is to show examples of how to use the `dtm` module.\n",
    "\n",
    "A \"document\" is a generic term for any text, but in the context of this module, it will refer to a tokenised text. Once it is possible to count the tokens in a document, it is also possible to calculate the number of terms (unique tokens) in that document. You can list these counts in a table with a term as the header of a column and a count as its value:\n",
    "\n",
    "| Doc                   | a    | abandoned | abatement | abbeyland | ... |\n",
    "|-----------------------|------|-----------|-----------|-----------|-----|\n",
    "| Pride_and_Prejudice   | 1940 | 0         | 1         | 0         | ... |\n",
    "\n",
    "If you have more than one document, you can put it on a separate line.\n",
    "\n",
    "| Doc                   | a    | abandoned | abatement | abbeyland | ... |\n",
    "|-----------------------|------|-----------|-----------|-----------|-----|\n",
    "| Pride_and_Prejudice   | 1940 | 0         | 1         | 0         | ... |\n",
    "| Sense_and_Sensibility | 2042 | 1         | 1         | 1         | ... |\n",
    "\n",
    "This is called a document-term matrix, or DTM for short. DTMs are typically a starting point for computational forms of text analysis. In this tutorial, we will learn how to use Lexos to generate a DTM and obtain statistics from its matrix.\n",
    "\n",
    "It is also important to note that each term is represented by a number, in this case, the number of times each term occurs. A list of such numeric representations is called a _vector_, and the task of transforming a list of document tokens into a DTM is performed by a _vectorizer_. The tables above use a very simple vectorizer to identify raw term counts, but a vectorizer's algorithm can be modified with various weighting and other properties to take account of specific circumstances such as variations in document length. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sample Data\n",
    "\n",
    "For this tutorial, we will load Jane Austen's _Pride and Prejudice_, tokenise it, and then cut it into ten segments, which we'll treat as ten separate documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from lexos.io.smart import Loader\n",
    "from lexos import tokenizer\n",
    "from lexos.cutter.ginsu import Ginsu\n",
    "\n",
    "loader = Loader()\n",
    "loader.load(\"../test_data/txt/Austen_Pride.txt\")\n",
    "text = re.sub(\"[\\r\\n|\\n]\", \" \", loader.texts[0]).strip()\n",
    "doc = tokenizer.make_doc(text)\n",
    "\n",
    "cutter = Ginsu()\n",
    "docs = cutter.splitn(doc, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the `DTM` Class\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "- `docs`: A list of spaCy docs or a list of token lists.\n",
    "- `labels`: A list of string labels for the documents. If not provided, the labels \"doc1\", \"doc2\", etc. will be used.\n",
    "\n",
    "The `DTM` class uses the Textacy package's `Vectorizer` to build a matrix of vectors. The default settings are as follows:\n",
    "\n",
    "- `tf_type`: \"linear\"\n",
    "- `idf_type`: None\n",
    "- `dl_type`: None\n",
    "- `norm`: None\n",
    "- `min_df`: 1\n",
    "- `max_df`: 1.0\n",
    "- `max_n_terms`: None\n",
    "- `vocabulary_terms`: None\n",
    "\n",
    "For explanations of the various parameters, see the <a href=\"https://textacy.readthedocs.io/en/latest/api_reference/representations.html#vectorizers\" target=\"_blank\">Vectorizers</a> in the Textacy documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.dtm import DTM\n",
    "\n",
    "# Without labels\n",
    "dtm = DTM(docs)\n",
    "print(f\"Default labels: {dtm.labels}\")\n",
    "\n",
    "# With labels\n",
    "labels=[\"Pride1\", \"Pride2\", \"Pride3\", \"Pride4\", \"Pride1\", \"Pride6\", \"Pride7\", \"Pride8\", \"Pride9\", \"Pride10\"]\n",
    "dtm = DTM(docs, labels=labels)\n",
    "print(f\"Assigned labels: {dtm.labels}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DTM.set_vectorizer()`\n",
    "\n",
    "Any of the vectorizer settings above can be changed with the `DTM.set_vectorizer()` method. However, it is important to rebuild the matrix after any change using `DTM.build()` to ensure that your `DTM` instance is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.set_vectorizer(tf_type=\"sqrt\", max_n_terms=100)\n",
    "dtm.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DTM.get_table()`\n",
    "\n",
    "Once you have a DTM, you can access the matrix conveniently (no pills required, Neo!) as a pandas dataframe. This displays a table of raw token counts.\n",
    "\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "- `transpose`: If `True`, terms are columns and docs are rows. Default = False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dtm.get_table()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Dataframe Usage\n",
    "\n",
    "This is a quick cheat sheet for accessing information in a pandas dataframe (referenced as `df`). It will be useful in following the cells below.\n",
    "\n",
    "- Get a single column as a list: `df[\"terms\"].values.tolist()`\n",
    "- Get a dataframe with only a few columns: `small_df = df[[\"terms\", \"Pride1\"]]`\n",
    "- Get the top 10 rows: `df.head(10)`\n",
    "- Get the bottom 10 rows: `df.tail(10)`\n",
    "- Get rows 5-10 in the table: `df[4:10]`\n",
    "- Sort by specific columns: `sorted_df = df.sort_values(by=[\"terms\", \"Pride1\"], ascending=False)`\n",
    "- Save to a CSV file (without the row indices): `df.to_csv(\"filename.csv\", index=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DTM.get_freq_table()`\n",
    "\n",
    "If you wish to show relative frequencies, use `DTM.get_freq_table()`.\n",
    "\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "- `rounding`: The number of digits to round floats. Default = 3.\n",
    "- `as_percent`: Whether to format the frequencies as percentages. Default = False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dtm.get_freq_table()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DTM.get_stats_table()`\n",
    "\n",
    "If you wish to calculate the sum, mean, and/or median calculated for each row, use `DTM.get_stats_table()`.\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "- `stats`: One or more of \"sum\", \"mean\", and/or \"median\" (use a list if more than one). Default = \"sum\".\n",
    "- `rounding`: The number of digits to round floats. Default = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dtm.get_stats_table(\"sum\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DTM.get_terms()`\n",
    "\n",
    "If you wish to get an alphabetical list of terms in the DTM, use `DTM.get_terms()`. Note that this function returns a generator that provides one value at a time. If you want the whole list, you will need to convert it to a list as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 20 Terms:\\n\")\n",
    "list(dtm.get_terms())[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DTM.get_term_counts()`\n",
    "\n",
    "If you wish to get a list of terms with their counts, use `DTM.get_terms()`. The output is a list of term-count tuples, but you can easily convert this to a pandas dataframe.\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "- `sort_by`: The column(s) to sort by in order of preference. Default = `[\"terms\", \"sum\"]`\n",
    "- `ascending`: Whether to sort values in ascending or descending order. Default = True.\n",
    "- `alg`: The algorithm used for sorting.\n",
    "\n",
    "Note that `DTM.get_term_counts()` generates a table using `DTM.get_stats_table()`, so it may sort by any column available in that table.\n",
    "\n",
    "The default sorting algorithm is whatever locale the user's operating system is set to, but it can be changed by setting `alg` to one of the locales used by the Python `natsort` package. A list of locales can be found in the <a href=\"https://natsort.readthedocs.io/en/stable/api.html#natsort.ns\" target=\"_blank\">natsort documentation</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"First 5 terms as a list of tuples:\\n\")\n",
    "print(dtm.get_term_counts()[0:5])\n",
    "\n",
    "import pandas as pd\n",
    "print(f\"\\nFirst 20 terms in a dataframe:\\n\")\n",
    "df = pd.DataFrame(dtm.get_term_counts(), columns=[\"Term\", \"Count\"])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Most Frequent and Least Frequent Terms\n",
    "\n",
    "Probably the easiest method to identify the most and least frequent terms is to get their sums using `DTM.get_stats_table()`, sort the resulting table, and getting the table's \"head\" or \"tail\". This is demonstrated in the cells below.\n",
    "\n",
    "Be aware that, if you have set the `min_df`, `max_df`, or `max_n_terms` parameters in your vectorizer, you may have already filtered some terms from your DTM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Frequent Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dtm.get_stats_table(\"sum\").sort_values(by=[\"sum\", \"terms\"], ascending=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least Frequent Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dtm.get_stats_table(\"sum\").sort_values(by=[\"sum\", \"terms\"], ascending=False)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lexos",
   "language": "python",
   "name": "lexos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff93cd05c7a11458fc6e692c465602a12d07b4d86c038fa25d5e533c12dcd222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
