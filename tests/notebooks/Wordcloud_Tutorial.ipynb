{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Worcloud` Tutorial\n",
    "   \n",
    "This notebook is to show examples of how to produce word cloud type visualisations of a document-term matrix. It starts out with a condensed version of the tutorial for the `dtm` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Construct a DTM\n",
    "\n",
    "For this tutorial, we will load Jane Austen's _Pride and Prejudice_, tokenise it, and then cut it into ten segments, which we'll treat as ten separate documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import re\n",
    "from lexos.io.smart import Loader\n",
    "from lexos import tokenizer\n",
    "from lexos.cutter.ginsu import Ginsu\n",
    "from lexos.dtm import DTM\n",
    "\n",
    "# Load the data\n",
    "loader = Loader()\n",
    "loader.load(\"../test_data/txt/Austen_Pride.txt\")\n",
    "text = re.sub(\"[\\r\\n|\\n]\", \" \", loader.texts[0]).strip()\n",
    "\n",
    "# Make a doc\n",
    "doc = tokenizer.make_doc(text)\n",
    "\n",
    "# Cut the god into 10 segments\n",
    "cutter = Ginsu()\n",
    "docs = cutter.splitn(doc, n=10)\n",
    "\n",
    "# Build a DTM with labels\n",
    "labels=[\"Pride1\", \"Pride2\", \"Pride3\", \"Pride4\", \"Pride5\", \"Pride6\", \"Pride7\", \"Pride8\", \"Pride9\", \"Pride10\"]\n",
    "dtm = DTM(docs, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Word Cloud\n",
    "\n",
    "The word cloud is generated using the Python <a href=\"https://amueller.github.io/word_cloud/\" target=\"_blank\">Wordcloud</a> package. Any options used by that library can be passed to the Lexos `wordcloud()` function as option with the `opts` parameter, as shown below.\n",
    "\n",
    "The resulting figure is plotted using <a href=\"https://matplotlib.org/\" target=\"_blank\">matplotlib</a>. It's options can be passed to the Lexos `wordcloud()` function with the `figure_opts` parameter.\n",
    "\n",
    "By default, word clouds are square, but you can round the corners to various degrees using the `round` parameter. You can also choose whether or not to display the word cloud when it is generated using the `show` parameter. If you supply a filename using the `filename` parameter, the word cloud will be saved to an image of file in a format determined by the file extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.visualization.cloud.wordcloud import wordcloud\n",
    "\n",
    "# Options for the Python Wordcloud package\n",
    "opts = {\n",
    "    \"max_words\": 2000,\n",
    "    \"background_color\": \"white\",\n",
    "    \"contour_width\": 0,\n",
    "    \"contour_color\": \"steelblue\"\n",
    "}\n",
    "\n",
    "# Options for controlling the matplotlib figure\n",
    "figure_opts = {\"figsize\": (15, 8)}\n",
    "\n",
    "# Generate the word cloud\n",
    "# cloud = wordcloud(\n",
    "#     dtm,\n",
    "#     opts=opts,\n",
    "#     figure_opts=figure_opts,\n",
    "#     round=150,\n",
    "#     show=True,\n",
    "#     # filename=\"wordcloud.png\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `wordcloud()` creates a word cloud based on the total term counts for all documents. If you wish to use a single or a subset of documents, use the `docs` parameter with a list the labels of docs you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = wordcloud(\n",
    "    dtm,\n",
    "    opts=opts,\n",
    "    figure_opts=figure_opts,\n",
    "    round=150,\n",
    "    show=True,\n",
    "    docs=[\"Pride1\", \"Pride2\", \"Pride3\", \"Pride4\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to a DTM, you can also provide `wordcloud()` with a raw text string (which will be tokenised by the `Wordcloud` package's internal tokenizer), as show below.\n",
    "\n",
    "You can also provide a list of token lists, a dict with the terms as keys and the counts/frequencies as values, or a dataframe with \"term\" and \"count\" or \"frequency\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = wordcloud(\n",
    "    loader.texts[0],\n",
    "    opts=opts,\n",
    "    figure_opts=figure_opts,\n",
    "    round=150,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Multicloud\n",
    "\n",
    "A multicloud is simply a series of word clouds (one for each document), arranged in a grid.\n",
    "\n",
    "Since `multicloud()` produces multiple subplots, there is a `title` parameter to give the entire figure a title and a `labels` parameter, which includes a list labels to be assigned to each subplot. The function takes the same `opts` and `figure_opts` parameters as `wordcloud()`.\n",
    "\n",
    "If a `filename` is provided, the entire plot will be saved. If `show=False`, the `multicloud()` function returns a list of word clouds. These can be saved individually by calling `to_file()` on them.\n",
    "\n",
    "As with `wordcloud()`, the `multicloud()` function accepts list of raw text strings, lists of dicts with the terms as keys and the counts/frequencies as values, or lists of dataframes with \"term\" and \"count\" or \"frequency\" columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import multicloud\n",
    "from lexos.visualization.cloud.wordcloud import multicloud\n",
    "\n",
    "# Generate the multicloud\n",
    "multicloud(\n",
    "    dtm,\n",
    "    title=\"My Multicloud\",\n",
    "    labels=labels,\n",
    "    ncols=3,\n",
    "    show=True,\n",
    "    opts=opts,\n",
    "    figure_opts=figure_opts,\n",
    "    round=150,\n",
    "    # filename=\"multicloud.png\"\n",
    ")\n",
    "\n",
    "# To save an individual cloud, use the following:\n",
    "\n",
    "# multi_cloud = multicloud(\n",
    "#     dtm,\n",
    "#     title=\"My Multicloud\",\n",
    "#     labels=labels,\n",
    "#     ncols=3,\n",
    "#     show=False,\n",
    "#     opts=opts,\n",
    "#     figure_opts=figure_opts,\n",
    "#     round=150,\n",
    "# )\n",
    "# multi_cloud[0].to_file(\"multicloud1.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lexos",
   "language": "python",
   "name": "lexos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff93cd05c7a11458fc6e692c465602a12d07b4d86c038fa25d5e533c12dcd222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
