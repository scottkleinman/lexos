{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Loader` Tutorial\n",
    "   \n",
    "Python has numerous ways to open files on your computer or download them from the internet. The Lexos `Loader` is a \"helper\" that invisibly takes care of many of the gotchas (like non-standard character encodings) so that you can get on with your work.\n",
    "\n",
    "The `Loader` is in active development and has a number of different versions the most advanced version is currently the \"smart\" version, and you'll see this referenced in the `import` statement below.\n",
    "\n",
    "You use the `Loader` by first instantiating a `Loader` class and then calling the `load()` function. This allows you to add texts to your loader multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the `Loader` Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.io.smart import Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Local File or a List of Local Files\n",
    "\n",
    "Notice in the list below that you can load `.txt`, `.docx`, or `.pdf` formats.\n",
    "\n",
    "When files are loaded into a `Loader`, their character encoding is automatically converted into UTF-8 format.\n",
    "\n",
    "You can see the names of the text you have uploaded by printing `Loader.names`. The filepaths can be accessed from `Loader.locations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single file\n",
    "data = \"../test_data/txt/Austen_Pride.txt\"\n",
    "\n",
    "loader1 = Loader()\n",
    "loader1.load(data)\n",
    "\n",
    "# A list files\n",
    "data = [\"../test_data/txt/Austen_Pride.txt\",\n",
    "        \"../test_data/docx/Austen_Sense_sm.docx\",\n",
    "        \"../test_data/pdf/Austen_Pride_sm.pdf\"]\n",
    "\n",
    "loader2 = Loader()\n",
    "loader2.load(data)\n",
    "\n",
    "print(f\"Loader 1: {loader1.names}\")\n",
    "print()\n",
    "print(f\"Loader 2: {loader2.locations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Texts in a `Loader`\n",
    "\n",
    "Texts are accessed with `Loader.texts`. This is a list, so, if you wish to access a single text, you must do so by its index in the list (e.g. `Loader.texts[0]`). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a single text (first 100 characters)\n",
    "print(f\"Text1:\")\n",
    "print(\"==========================\")\n",
    "print(f\"{loader2.texts[0][0:100]}...\\n\")\n",
    "\n",
    "# Print multiple texts (first 100 characters)\n",
    "for i, item in enumerate(loader2.texts):\n",
    "    print(f\"Text{i + 1}:\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"{item[0:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also loop through the `Loader` directly an print the text of each item with the `text` property. You can also access the `name`, `location`, and `source` of each of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through the Loader\n",
    "for i, item in enumerate(loader2):\n",
    "    print(f\"Text{i + 1}: {item.name}\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"{item.text[0:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Local Directories or Zip Files   \n",
    "\n",
    "Directories or zip files containing files of `.txt`, `.docx`, and `.pdf` extenstions can be loaded just like other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the files in the docx directory\n",
    "loader1 = Loader()\n",
    "loader1.load(\"../test_data/docx\")\n",
    "\n",
    "# Get all the files in a zip file\n",
    "loader2.load(\"../test_data/zip/txt.zip\")\n",
    "\n",
    "# Print the first 100 characters of the first file in the directory\n",
    "print(loader1.texts[0][0:100])\n",
    "\n",
    "# Print the first 100 characters of the first file in the zip file\n",
    "print(loader1.texts[0][0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Texts from a URL\n",
    "\n",
    "Use the same technique to download a text or texts from a url or a list of urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Loader()\n",
    "loader.load(\"https://www.gutenberg.org/files/84/84-0.txt\")\n",
    "\n",
    "print (loader.texts[0][0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Dataset\n",
    "\n",
    "Text analysis often requires datasets consisting of a large number of documents. Such datasets are often packaged with multiple documents in a single file in a variety for formats. The `DatasetLoader` class provides a convenient means of loading many common formats. Valid inputs are:\n",
    "\n",
    "- Plain text files with one document per line\n",
    "- CSV and TSV files with one document per line\n",
    "- Excel files\n",
    "- JSON files\n",
    "- JSONL files (newline-delimited JSON)\n",
    "- Folders and zip archives containing files in the above formats\n",
    "- Urls to files in the above formats\n",
    "\n",
    "A simple example of the use of the `DatasetLoader` class is given below. In this example we have a plain text file with one document per line and no titles. If we try to load it with `DatasetLoader(source)`, we will receive an error. In order to get around this problem, we supply a list of titles using the `labels` parameter. If you do not know the number of lines in your dataset, you can use `labels=[1]`, and you will get an error telling you how many lines are in the file (and thus how many labels you need to supply).\n",
    "\n",
    "Note that the other formats listed above often require you to specify metadata information. These requirements are discussed further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.io.dataset import DatasetLoader\n",
    "\n",
    "source = \"../test_data/datasets/base.txt\"\n",
    "labels = [\n",
    "    \"Ainsworth_Guy_Fawkes\",\n",
    "    \"Ainsworth_Lancashire_Witches\",\n",
    "    \"Ainsworth_Old_Saint_Pauls\",\n",
    "    \"Ainsworth_Tower_of_London\",\n",
    "    \"Ainsworth_Windsor_Castle\"\n",
    "]\n",
    "\n",
    "dataset_loader = DatasetLoader(source, labels=labels)\n",
    "\n",
    "# Print a list of titles in the dataset\n",
    "print(dataset_loader.names)\n",
    "\n",
    "print(\"\\n==========================\\n\")\n",
    "\n",
    "# Iterate through the DatasetLoader and print items from its data dict\n",
    "for item in dataset_loader:\n",
    "    print(f\"{item['title']}: {item['text'][0:50]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the titles and texts using `DatasetLoader.names` and `DatasetLoader.texts`, or you can access them together in a dict as `DatasetLoader.data`.\n",
    "\n",
    "The code below loads a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../test_data/datasets/csv_valid.csv\"\n",
    "\n",
    "dataset_loader = DatasetLoader(source)\n",
    "\n",
    "for item in dataset_loader: \n",
    "    print(f\"{item['title']}: {item['text'][0:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the test file is called `csv_valid.csv`. This naming convention indicates that the first line of the CSV file is \"title,text\" &mdash; the two headers required by the `DatasetLoader`. If your CSV file has different headers for the title and text, you can indicate the headers that should be converted with `title_col` and `text_col`. You can see this in action in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../test_data/datasets/csv_invalid.csv\"\n",
    "\n",
    "dataset_loader = DatasetLoader(source, title_col=\"label\", text_col=\"content\")\n",
    "\n",
    "for item in dataset_loader: \n",
    "    print(f\"{item['title']}: {item['text'][0:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a tab-separated file (TSV), simply add the parameter `sep=\"\\t\"`.\n",
    "\n",
    "The `DatasetLoader` will also load Excel files and takes the `title_col` and `text_col` parameters.\n",
    "\n",
    "Loading a file from JSON works the same way, except that, if you don't have `title` and `text` fields, you should specify which fields should be used with the `title_field` and `text_field` parameters. Additionally, if your JSON is newline-delimited, you should specify `lines=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../test_data/datasets/json_valid.json\"\n",
    "# # source = \"../test_data/datasets/json_invalid.json\"\n",
    "# source = \"../test_data/datasets/jsonl_valid.jsonl\"\n",
    "\n",
    "dataset_loader = DatasetLoader(source, title_field=\"label\", text_field=\"content\")\n",
    "\n",
    "for item in dataset_loader: \n",
    "    print(f\"{item['title']}: {item['text'][0:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Dataset` Class\n",
    "\n",
    "`DatasetLoader` is actually a wrapper for the `Dataset` class, which has parsing methods for different dataset formats. These methods can be called individually with commands like `dataset = Dataset.parse_string(source, labels=LABELS)`. The available methods are:\n",
    "\n",
    "- `parse_string()`\n",
    "- `parse_csv()`\n",
    "- `parse_excel()`\n",
    "- `parse_json()`\n",
    "- `parse_jsonl()`\n",
    "\n",
    "Each method takes the same arguments described for the `DatasetLoader` class.\n",
    "\n",
    "Apart from `parse_string()`, these methods read their source using methods from the pandas library: `pandas.read_csv()`, `pandas.read_excel()`, `pandas.read_json()`. Any keywords accepted by those methods can also be passed through their equivalent `Dataset` methods.\n",
    "\n",
    "An example is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.io.dataset import Dataset\n",
    "\n",
    "source = \"../test_data/datasets/csv_valid.csv\"\n",
    "\n",
    "dataset = Dataset.parse_csv(source)\n",
    "\n",
    "for item in dataset:\n",
    "    print(f\"{item['title']}: {item['text'][0:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Datasets to a Standard Lexos Loader\n",
    "\n",
    "If you already have a `Loader`, it is easy to add datasets to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the loaders\n",
    "from lexos.io.smart import Loader\n",
    "from lexos.io.dataset import Dataset, DatasetLoader\n",
    "\n",
    "# Create and empty `Loader`\n",
    "loader = Loader()\n",
    "\n",
    "# Create a `DatasetLoader` and load a dataset\n",
    "dataset_loader = DatasetLoader(source, labels=labels)\n",
    "\n",
    "# Load a dataset with `Dataset`\n",
    "dataset = Dataset.parse_csv(source)\n",
    "\n",
    "# Add the text and names for each dataset to the standard loader\n",
    "for item in [dataset_loader, dataset]:\n",
    "    loader.names.extend(item.names)\n",
    "    loader.texts.extend(item.texts)\n",
    "\n",
    "# Print the names of the first 10 documents\n",
    "print(loader.names[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lexos",
   "language": "python",
   "name": "lexos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff93cd05c7a11458fc6e692c465602a12d07b4d86c038fa25d5e533c12dcd222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
