{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb8e213-bdf2-4a9d-8a62-32e0dcda5487",
   "metadata": {},
   "source": [
    "# Test the Datasets Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a5dd11-6fee-45f6-9586-3d531a489982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.io.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24521a-fc41-49d6-b637-89912f58d5f1",
   "metadata": {},
   "source": [
    "## Configure Dataset Type\n",
    "\n",
    "- headerlines lines\n",
    "- lines with headers\n",
    "- headerless csv\n",
    "- csv\n",
    "- json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba507913-3ca4-4998-a420-4aa55e163440",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_types = {\n",
    "    \"raw_str_no_headers\": \"Test\\nTest\",\n",
    "    \"local_path\": \"../test_data/datasets/Austen.txt\",\n",
    "    \"local_csv\": \"../test_data/datasets/Austen.csv\",\n",
    "    \"local_tsv\": \"../test_data/datasets/Austen_valid_headers.tsv\",\n",
    "    \"local_tsv_no_headers\": \"../test_data/datasets/Austen.tsv\",\n",
    "    \"local_tsv_invalid\": \"../test_data/datasets/Austen_invalid_headers.tsv\",\n",
    "    \"local_json\": \"../test_data/datasets/Austen.json\",\n",
    "    \"local_jsonl\": \"../test_data/datasets/Austen_nl.jsonl\",\n",
    "    \"local_json_invalid\": \"../test_data/datasets/Austen_invalid_fields.json\",\n",
    "    \"zipped_lineated_text\": \"../test_data/datasets/lineated_text.zip\"\n",
    "}\n",
    "\n",
    "source = dataset_types[\"local_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00857b63-800f-433f-bed8-8e393bca7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.parse_lines(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df5eb3-a90b-4875-ba94-bcb90b3efde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c28a34ec-6000-44cb-8fd4-f43310fd6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dataset2.py.\n",
    "\n",
    "This class currently supports single files of the following formats:\n",
    "\n",
    "    - lineated text files, csv, tsv, json, and jsonl files\n",
    "    - lineated text strings\n",
    "\n",
    "To Do:\n",
    "\n",
    "    - Test support for multiple files/strings (it should work as long as all files are of the same format)\n",
    "    - Add support for csv, tsv, json, and jsonl strings\n",
    "\"\"\"\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from IPython.display import display # Remove for production\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "import tempfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from smart_open import open\n",
    "\n",
    "\n",
    "class Dataset(BaseModel):\n",
    "    \"\"\"Dataset class.\"\"\"\n",
    "\n",
    "    df: Optional[pd.DataFrame] = None\n",
    "    data: Optional[List[Dict[str, str]]] = None\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "#     @property\n",
    "#     def df(self) -> pd.DataFrame:\n",
    "#         \"\"\"Return the dataframe of the object data.\n",
    "\n",
    "#         Returns:\n",
    "#             pd.DataFrame: The dataframe of the object data.\n",
    "#         \"\"\"\n",
    "#         if self.data and not self.df:\n",
    "#             return pd.DataFrame(self.data)\n",
    "\n",
    "    @property\n",
    "    def locations(self) -> List[str]:\n",
    "        \"\"\"Return the locations of the object data.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: The locations of the object data.\n",
    "        \"\"\"\n",
    "        if \"locations\" in self.df.columns:\n",
    "            return self.df[\"locations\"].values.tolist()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def names(self) -> List[str]:\n",
    "        \"\"\"Return the names of the object data.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: The names of the object data.\n",
    "        \"\"\"\n",
    "        return self.df[\"title\"].values.tolist()\n",
    "\n",
    "    @property\n",
    "    def texts(self) -> List[str]:\n",
    "        \"\"\"Return the texts of the object data.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: The texts of the object data.\n",
    "        \"\"\"\n",
    "        return self.df[\"text\"].values.tolist()\n",
    "\n",
    "    \n",
    "class DatasetLoader:\n",
    "    \"\"\"Loads a dataset.\n",
    "    \n",
    "    Usage:\n",
    "        loader = DatasetLoader(source)\n",
    "        dataset = loader.dataset\n",
    "        \n",
    "    Notes:\n",
    "        Different types of data may require different keyword parameters. Error messages\n",
    "        provide some help in identifying what keywords are required.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        source: Any, \n",
    "        labels: List[str] = None,\n",
    "        locations: Optional[List[str]] = None,\n",
    "        title_col: Optional[str] = None,\n",
    "        text_col: Optional[str] = None,\n",
    "        location_col: Optional[str] = None,\n",
    "        **kwargs: Dict[str, str],\n",
    "    ) -> Union[Dataset, List[Dataset]]:\n",
    "        \"\"\"Initialise the loader.\n",
    "        \n",
    "        Args:\n",
    "            source (Any): The source type to detect.\n",
    "            labels (List[str]): The labels to use.\n",
    "            locations (Optional[List[str]]): The locations of the texts.\n",
    "            title_col (str): The name of the column containing the titles.\n",
    "            text_col (str): The name of the column containing the texts.\n",
    "            location_col (str): The name of the column containing the locations.\n",
    "\n",
    "        Return:\n",
    "            Union[Dataset, List[Dataset]]: A Dataset object.\n",
    "        \"\"\"\n",
    "        if isinstance(source, list):\n",
    "            self.data = [\n",
    "                Dataset(df=self.load(item, labels, locations, title_col, text_col, location_col, **kwargs))\n",
    "                for item in source\n",
    "            ]\n",
    "        else:\n",
    "            df = self.load(source, labels, locations, title_col, text_col, location_col, **kwargs)\n",
    "            self.data = Dataset(df=df)\n",
    "\n",
    "    def _detect_source_type(\n",
    "        self,\n",
    "        source: Any,\n",
    "        labels: List[str] = None,\n",
    "        locations: Optional[List[str]] = None,\n",
    "        title_col: Optional[str] = None,\n",
    "        text_col: Optional[str] = None,\n",
    "        location_col: Optional[str] = None,\n",
    "        **kwargs: Dict[str, str],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Detect the source type of the given source type.\n",
    "\n",
    "        Args:\n",
    "            source (Any): The source type to detect.\n",
    "            labels (List[str]): The labels to use.\n",
    "            locations (Optional[List[str]]): The locations of the texts.\n",
    "            title_col (str): The name of the column containing the titles.\n",
    "            text_col (str): The name of the column containing the texts.\n",
    "            location_col (str): The name of the column containing the locations.\n",
    "\n",
    "        Return:\n",
    "            str: The detected source type.\n",
    "        \"\"\"\n",
    "        if isinstance(source, list):\n",
    "            print(\"Lists are not supported yet.\")\n",
    "            return \"list\"\n",
    "        elif isinstance(source, str):\n",
    "            lines = source.split(\"\\n\")\n",
    "            if len(lines) > 1:\n",
    "                df = self.load_string(lines, labels)\n",
    "            else:\n",
    "                df = self.load_file(str(source), labels, locations, title_col, text_col, location_col, **kwargs)\n",
    "            return df\n",
    "        else:\n",
    "            raise Exception(f\"Unknown source type: {source}\")\n",
    "\n",
    "    def load(\n",
    "        self,\n",
    "        source: Any,\n",
    "        labels: List[str] = None,\n",
    "        locations: Optional[List[str]] = None,\n",
    "        title_col: Optional[str] = None,\n",
    "        text_col: Optional[str] = None,\n",
    "        location_col: Optional[str] = None,\n",
    "        **kwargs: Dict[str, str]\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Load the given file.\n",
    "\n",
    "        Args:\n",
    "            source (Any): The source the data to load.\n",
    "            labels (List[str]): The labels to use.\n",
    "            locations (Optional[List[str]]): The locations of the texts.\n",
    "            title_col (str): The name of the column containing the titles.\n",
    "            text_col (str): The name of the column containing the texts.\n",
    "            location_col (str): The name of the column containing the locations.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The loaded data.\n",
    "        \"\"\"\n",
    "        df = self._detect_source_type(source, labels, locations, title_col, text_col, location_col, **kwargs)\n",
    "        return df\n",
    "\n",
    "    def load_file(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        labels: List[str] = None,\n",
    "        locations: Optional[List[str]] = None,\n",
    "        title_col: Optional[str] = None,\n",
    "        text_col: Optional[str] = None,\n",
    "        location_col: Optional[str] = None,\n",
    "        **kwargs: Dict[str, str]\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Load the given file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the file to load.\n",
    "            labels (List[str]): The labels to use.\n",
    "            locations (Optional[List[str]]): The locations of the texts.\n",
    "            title_col (str): The name of the column containing the titles.\n",
    "            text_col (str): The name of the column containing the texts.\n",
    "            location_col (str): The name of the column containing the locations.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The loaded data.\n",
    "        \"\"\"\n",
    "        if Path(file_path).exists():\n",
    "            mime_type, _ = mimetypes.guess_type(file_path)\n",
    "            # Lineated text\n",
    "            if mime_type == \"text/plain\":\n",
    "                with open(file_path) as f:\n",
    "                    return self.load_string(list(f.readlines()), labels)\n",
    "            # CSV/TSV\n",
    "            elif mime_type in [\"text/csv\", \"text/tsv\", \"application/vnd.ms-excel\", \"text/tab-separated-values\"]:\n",
    "                if labels:\n",
    "                    df = pd.read_csv(file_path, header=None, **kwargs)\n",
    "                    df.columns = labels\n",
    "                else:\n",
    "                    df = pd.read_csv(file_path, **kwargs)\n",
    "                if title_col:\n",
    "                    df = df.rename(columns={title_col: \"title\"})\n",
    "                if text_col:\n",
    "                    df = df.rename(columns={text_col: \"text\"})\n",
    "                if location_col:\n",
    "                    df[\"locations\"] = [file_path] * df.shape[1]\n",
    "                if \"title\" not in df.columns or \"text\" not in df.columns:\n",
    "                    err = (\n",
    "                        \"CSV or TSV files must contain columns named `title` and `text`. \",\n",
    "                        \"You can convert the names of existing column to these with the \",\n",
    "                        \"`title_col` and `text_col` parameters. If your file has no column \",\n",
    "                        \"headers, you can supply a list with the `labels` parameter.\",\n",
    "                    )\n",
    "                    raise Exception(\"\".join(err))\n",
    "                return df\n",
    "            # JSON/JSONL\n",
    "            elif mime_type == \"application/json\" or file_path.endswith(\".jsonl\"):\n",
    "                df = pd.read_json(file_path, **kwargs)\n",
    "                if title_col:\n",
    "                    df = df.rename(columns={title_col: \"title\"})\n",
    "                if text_col:\n",
    "                    df = df.rename(columns={text_col: \"text\"})\n",
    "                if location_col:\n",
    "                    df[\"locations\"] = [file_path] * df.shape[1]\n",
    "                if \"title\" not in df.columns or \"text\" not in df.columns:\n",
    "                    err = (\n",
    "                        \"JSON and JSONL files must contain fields named `title` and `text`. \",\n",
    "                        \"You can convert the names of existing fields to these with the \",\n",
    "                        \"`title_col` and `text_col` parameters.\",\n",
    "                    )\n",
    "                    raise Exception(\"\".join(err))\n",
    "                return df\n",
    "            # Zip\n",
    "            elif mime_type in [\"application/zip\", \"application/x-zip-compressed\"]:\n",
    "                return self.load_zip(file_path, labels, locations, title_col, text_col, location_col, **kwargs)\n",
    "            else:\n",
    "                raise Exception(f\"Unknown file type: {mime_type}\")\n",
    "\n",
    "    def load_string(self, source: str, labels: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load the given string.\n",
    "\n",
    "        Args:\n",
    "            source (str): The string to load.\n",
    "            labels (List[str]): The labels to use.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The loaded data.\n",
    "        \"\"\"\n",
    "        if not labels:\n",
    "            raise Exception(\"Please use the `labels` argument to provide a list of labels for each row in your data.\")\n",
    "        elif len(labels) != len(source):\n",
    "            raise Exception(\"The number of labels does not match the number of lines in your data.\")\n",
    "        else:\n",
    "            data = [{\"title\": labels[i], \"text\": line} for i, line in enumerate(source)]\n",
    "            df = pd.DataFrame(data, columns=[\"title\", \"text\"])\n",
    "            return df\n",
    "\n",
    "    def load_zip(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        labels: List[str] = None,\n",
    "        locations: Optional[List[str]] = None,\n",
    "        title_col: Optional[str] = None,\n",
    "        text_col: Optional[str] = None,\n",
    "        location_col: Optional[str] = None,\n",
    "        **kwargs: Dict[str, str],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load a zip file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the file to load.\n",
    "            labels (List[str]): The labels to use.\n",
    "            locations (Optional[List[str]]): The locations of the texts.\n",
    "            title_col (str): The name of the column containing the titles.\n",
    "            text_col (str): The name of the column containing the texts.\n",
    "            location_col (str): The name of the column containing the locations.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The loaded data.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame([], columns=[\"title\", \"text\"])\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            with zipfile.ZipFile(f) as zip:\n",
    "                with tempfile.TemporaryDirectory() as tempdir:\n",
    "                    zip.extractall(tempdir)\n",
    "                    new_dfs = []\n",
    "                    for tmp_path in Path(tempdir).glob(\"**/*\"):\n",
    "                        if (\n",
    "                            tmp_path.is_file()\n",
    "                            and not tmp_path.suffix == \"\"\n",
    "                            and not str(tmp_path).startswith(\"__MACOSX\")\n",
    "                            and not str(tmp_path).startswith(\".ds_store\")\n",
    "                        ):\n",
    "                            new_dfs.append(load_file(tmp_path, labels, locations, title_col, text_col, location_col, **kwargs))\n",
    "                    df = pd.concat(new_dfs, ignore_index=True, sort=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6956ef98-7c51-4d7f-b4c3-02eff17948f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text1</td>\n",
       "      <td>Pride and Prejudice by Jane Austen Chapter 1 I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text2</td>\n",
       "      <td>SENSE AND SENSIBILITY by Jane Austen (1811) CH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title                                               text\n",
       "0  text1  Pride and Prejudice by Jane Austen Chapter 1 I...\n",
       "1  text2  SENSE AND SENSIBILITY by Jane Austen (1811) CH..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset(data=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DatasetLoader(source, labels=[\"text1\", \"text2\"])\n",
    "loader.data\n",
    "# for dataset in loader.data:\n",
    "#     display(dataset.df)\n",
    "# dataset = Dataset(id=1, name=\"Joe\")\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8980b99f-f390-4fd8-bf80-ef055e5ae84d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DatasetLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[1;32m----> 2\u001b[0m doink \u001b[38;5;241m=\u001b[39m Dataset(df\u001b[38;5;241m=\u001b[39m\u001b[43mloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdf)\n\u001b[0;32m      3\u001b[0m doink\u001b[38;5;241m.\u001b[39mdf\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DatasetLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data = [{\"title\": \"text1\", \"text\": \"Test\"}, {\"title\": \"text1\", \"text\": \"Test\"}]\n",
    "doink = Dataset(df=loader[0].data.df)\n",
    "doink.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df12def-4396-479b-8117-ad5e5ceb7b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lexos",
   "language": "python",
   "name": "lexos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
