{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13eb0543-86b4-40a3-93fc-969242b79349",
   "metadata": {},
   "source": [
    "# Lexos Visualizations\n",
    "\n",
    "This script does the following:\n",
    "\n",
    "1. Creates spaCy docs from a list of text files.\n",
    "2. Converts the tokens to lower case and filters them to remove digits, punctuation, and whitespace.\n",
    "3. Tests that the loader is working properly.\n",
    "4. Store data in a document term matrix.\n",
    "5. Generates a dendogram from the dtm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bf0c8-bb4c-4cd7-aca5-4e30dd94c522",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure a list of file paths, the labels you wish to use for each document, and the language model you wish to use to parse the texts.\n",
    "\n",
    "Note that converting long texts to spaCy docs can take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6c0ea8-f075-4cd5-81a5-61402b5f4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own data\n",
    "data = [\n",
    "    r\"C:\\Users\\jack\\OneDrive\\Documents\\School\\summer22\\LexosRepo\\lexos\\tests\\test_data\\txt\\Austen_Pride.txt\",\n",
    "    r\"C:\\Users\\jack\\OneDrive\\Documents\\School\\summer22\\LexosRepo\\lexos\\tests\\test_data\\txt\\Austen_Sense.txt\"\n",
    "]\n",
    "labels = [\"Pride\", \"Sense\"]\n",
    "model = \"en_core_web_sm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb3b32-adca-49ee-88b0-0d907c29de90",
   "metadata": {},
   "source": [
    "## Import Lexos API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a065ff-e19c-4b1c-acda-e0b2222b54fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack\\OneDrive\\Documents\\School\\summer22\\LexosRepo\\lexos\\lexos\n"
     ]
    }
   ],
   "source": [
    "# Set local import path\n",
    "import os\n",
    "import sys\n",
    "LEXOS_PATH = \"lexos\"\n",
    "if \"NOTEBOOK_INITIATED_FLAG\" not in globals():\n",
    "    NOTEBOOK_INITIATED_FLAG = True\n",
    "    try:\n",
    "        module_path = os.path.join(os.path.dirname(__file__), os.pardir)\n",
    "    except:\n",
    "        module_path = os.path.abspath(os.path.join(LEXOS_PATH))\n",
    "        %cd lexos\n",
    "        %pwd\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "        \n",
    "# Import Lexos API modules\n",
    "from lexos.io.basic import Loader\n",
    "from lexos import tokenizer\n",
    "from lexos.dtm import DTM\n",
    "from lexos.cutter import Ginsu\n",
    "try:\n",
    "    from lexos.cluster.dendrogram import Dendrogram\n",
    "except ImportError:\n",
    "    print(\"Dendogram not imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb3bfd-0393-451d-82d5-e98a4ade28c6",
   "metadata": {},
   "source": [
    "## Load Texts and Convert to spaCy Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47e8055-22b9-4f83-bc0a-ece1d20c58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loader and load the data\n",
    "loader = Loader()\n",
    "loader.load(data)\n",
    "\n",
    "# Make the docs -- currently takes a long time with full novels\n",
    "docs = tokenizer.make_docs(loader.texts, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a5a284-dd21-42f9-bc0b-db4e5c1191d4",
   "metadata": {},
   "source": [
    "## Ensure Loader is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bccfbfd-e43d-407d-92bc-ed1293573ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pride and Prejudice\n",
      "by Jane Austen\n",
      "Chapter 1\n",
      "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
      "However little known the feelings or views of such a man\n",
      "\n",
      "\n",
      "SENSE AND SENSIBILITY\n",
      "by Jane Austen\n",
      "(1811)\n",
      "CHAPTER 1\n",
      "The family of Dashwood had long been settled in Sussex. Their estate\n",
      "was large, and their residence was at Norland Park, in the centre of\n",
      "their property, where,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(docs):\n",
    "    print(text[0:50])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d7bb7-fe60-4312-ab2e-1b9c3ef7cd55",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faec189b-bae9-4331-a781-50cabea929f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.tokenizer.lexosdoc import LexosDoc\n",
    "\n",
    "lexos_doc = LexosDoc(docs)\n",
    "tokens = lexos_doc.get_tokens()\n",
    "#print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a48c52-26bf-4ca4-b9bc-9ed5fa497160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.representations.vectorizers import Vectorizer\n",
    "from lexos.tokenizer.lexosdoc import LexosDoc\n",
    "\n",
    "vectorizer = Vectorizer(\n",
    "    tf_type=\"linear\",\n",
    "    idf_type=None,\n",
    "    norm=None\n",
    ")\n",
    "\n",
    "tokenised_docs = (LexosDoc(doc).get_tokens() for doc in docs)\n",
    "doc_term_matrix = vectorizer.fit_transform(tokenised_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3e2e3a-da2a-45b4-bcf0-072ad0115d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t119323\n",
      "  (0, 3)\t499\n",
      "  (0, 4)\t3508\n",
      "  (0, 10)\t747\n",
      "  (0, 20)\t18\n",
      "  (0, 21)\t18\n",
      "  (0, 22)\t30\n",
      "  (0, 23)\t9117\n",
      "  (0, 24)\t1424\n",
      "  (0, 29)\t6171\n",
      "  (0, 31)\t20\n",
      "  (0, 46)\t19\n",
      "  (0, 59)\t16\n",
      "  (0, 70)\t16\n",
      "  (0, 81)\t18\n",
      "  (0, 92)\t10\n",
      "  (0, 95)\t6\n",
      "  (0, 97)\t7\n",
      "  (0, 98)\t6\n",
      "  (0, 99)\t133\n",
      "  (0, 100)\t1538\n",
      "  (0, 101)\t462\n",
      "  (0, 102)\t446\n",
      "  (0, 411)\t145\n",
      "  (0, 544)\t2555\n",
      "  :\t:\n",
      "  (1, 22)\t3\n",
      "  (1, 23)\t9900\n",
      "  (1, 24)\t2725\n",
      "  (1, 29)\t4918\n",
      "  (1, 31)\t19\n",
      "  (1, 46)\t16\n",
      "  (1, 59)\t15\n",
      "  (1, 70)\t15\n",
      "  (1, 81)\t6\n",
      "  (1, 92)\t5\n",
      "  (1, 95)\t6\n",
      "  (1, 97)\t6\n",
      "  (1, 98)\t5\n",
      "  (1, 99)\t66\n",
      "  (1, 100)\t1572\n",
      "  (1, 101)\t452\n",
      "  (1, 102)\t554\n",
      "  (1, 411)\t254\n",
      "  (1, 544)\t2438\n",
      "  (1, 602)\t431\n",
      "  (1, 749)\t263\n",
      "  (1, 1022)\t601\n",
      "  (1, 1108)\t2\n",
      "  (1, 1109)\t2\n",
      "  (1, 1111)\t39892\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix = vectorizer.fit_transform(tokens)\n",
    "print (doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2907daf-db84-4c42-99c7-2aec9b564976",
   "metadata": {},
   "source": [
    "## Cut texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42af011c-2801-4b66-a5ee-050a3675dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 2\n",
      "\n",
      "Doc 1:\n",
      "\n",
      "Segment 1:\n",
      "\n",
      " Pride and Prejudice\n",
      "by \n",
      "\n",
      "Segment 2:\n",
      "\n",
      "report which shortly prev\n",
      "\n",
      "Segment 3:\n",
      "\n",
      "that the authority of a s\n",
      "\n",
      "Doc 2:\n",
      "\n",
      "Segment 1:\n",
      "\n",
      "SENSE AND SENSIBILITY\n",
      "by\n",
      "\n",
      "Segment 2:\n",
      "\n",
      "many years date. He was u\n",
      "\n",
      "Segment 3:\n",
      "\n",
      "other, I forget\n",
      "who. So \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cutter = Ginsu()\n",
    "list_of_segmented_docs = cutter.splitn(docs, n=3)\n",
    "\n",
    "print(f\"Number of docs: {len(list_of_segmented_docs)}\\n\")\n",
    "for i, segmented_doc in enumerate(list_of_segmented_docs):\n",
    "    print(f\"Doc {i+1}:\\n\")\n",
    "    for j, segment in enumerate(segmented_doc):\n",
    "        print(f\"Segment {j+1}:\\n\")\n",
    "        print(segment.text[0:25])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa1e23-2477-421e-9051-f9d6c9360582",
   "metadata": {},
   "source": [
    "## Initiate DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "363d00a4-6aae-4e45-af19-dd2cc2ff832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.dtm import DTM\n",
    "labels = [\"Pride_and_Prejudice\", \"Sense_and_Sensibility\"]\n",
    "dtm = DTM(docs, labels)\n",
    "\n",
    "labels = [\"Pride1\", \"Pride2\", \"Pride3\", \"Sense1\", \"Sense2\", \"Sense3\"]\n",
    "#result = [doc.text for doc in result]\n",
    "#print (result[0])\n",
    "dtm2 = DTM(list_of_segmented_docs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62f4d8-131f-4052-a5c0-e44d84486fb8",
   "metadata": {},
   "source": [
    "## Create Dendogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3233b1-0782-4807-939d-d5845178899f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "7 columns passed, passed data had 3 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:982\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 982\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:1030\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m   1031\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1032\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1033\u001b[0m     )\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi_list:\n\u001b[0;32m   1035\u001b[0m \n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 7 columns passed, passed data had 3 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dendrogram \u001b[38;5;241m=\u001b[39m \u001b[43mDendrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtm2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\School\\summer22\\LexosRepo\\lexos\\lexos\\cluster\\dendrogram.py:81\u001b[0m, in \u001b[0;36mDendrogram.__init__\u001b[1;34m(self, dtm, labels, metric, method, truncate_mode, color_threshold, get_leaves, orientation, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_rotation, leaf_font_size, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color, title, figsize, show)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow \u001b[38;5;241m=\u001b[39m show\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Get the dtm table\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtm_table \u001b[38;5;241m=\u001b[39m \u001b[43mdtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Use default labels from the DTM table\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\School\\summer22\\LexosRepo\\lexos\\lexos\\dtm\\__init__.py:55\u001b[0m, in \u001b[0;36mDTM.get_table\u001b[1;34m(self, transpose)\u001b[0m\n\u001b[0;32m     53\u001b[0m     [row\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m freq]\n\u001b[0;32m     54\u001b[0m     rows\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[1;32m---> 55\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mterms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transpose:\n\u001b[0;32m     57\u001b[0m     df\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterms\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m}, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"ensure_index\" has incompatible type\u001b[39;00m\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;66;03m# \"Collection[Any]\"; expected \"Union[Union[Union[ExtensionArray,\u001b[39;00m\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;66;03m# ndarray], Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[0;32m    720\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    729\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    730\u001b[0m         arrays,\n\u001b[0;32m    731\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    734\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    735\u001b[0m     )\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:519\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 519\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:883\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    880\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    881\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 883\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:985\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    982\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 985\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    988\u001b[0m     contents \u001b[38;5;241m=\u001b[39m _convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 7 columns passed, passed data had 3 columns"
     ]
    }
   ],
   "source": [
    "dendrogram = Dendrogram(dtm2, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea2fb9-2679-4028-967f-cf7d05431736",
   "metadata": {},
   "source": [
    "## Create WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e865e9-ca95-48d5-8399-726aa7ca28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.visualization.cloud.wordcloud import multicloud\n",
    "labels = dtm.get_table().columns.tolist()[1:]\n",
    "multicloud(dtm, docs=None, opts=None, ncols=3, title=None, labels=None, show=True, figure_opts=None, round=None, filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418622ab-0ee6-419a-88c9-3284132253c9",
   "metadata": {},
   "source": [
    "## Create BubbleViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012ab72-6ddd-4067-84be-7613c052e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.visualization.bubbleviz import bubbleviz\n",
    "bubbleviz(dtm)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2aa7953f390f28e7e50d668f5dd71a50654ba94f4b9e6876e74ed7ed7caa2611"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
