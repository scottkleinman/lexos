{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a99461",
   "metadata": {},
   "source": [
    "# K-Means Clustering Tutorial\n",
    "\n",
    "This tutorial demonstrates how to use the Lexos `KMeans` class with a preprocessed document-term matrix (DTM). You will learn how to perform clustering, visualize the results, and export your outputs for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0567fe18",
   "metadata": {},
   "source": [
    "## Load Your Data\n",
    "\n",
    "In this step, we load all the text files that you want to cluster. Each file is treated as one document.\n",
    "\n",
    "The code looks for `.txt` files in the `FilesToUse` folder and loads them in alphabetical order.\n",
    "\n",
    "You'll see confirmation of how many documents were loaded and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from lexos.io.loader import Loader\n",
    "\n",
    "# Get a sorted list of all text files in the \"FilesToUse\" directory\n",
    "file_paths = sorted(glob.glob(\"FilesToUse/*.txt\"))\n",
    "\n",
    "# Load the documents using the Loader class\n",
    "loader = Loader()\n",
    "loader.load(paths=file_paths)\n",
    "\n",
    "print(f\"Loaded {len(loader.texts)} documents: {loader.names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd738dc",
   "metadata": {},
   "source": [
    "Now we will convert our texts into spaCy Docs. Since our test files are novels, we'll increase maximum character length to 2,000,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed43271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexos.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "docs = tokenizer.make_docs(texts=loader.texts, max_length=2_000_000)\n",
    "\n",
    "# Convert the generator to a list\n",
    "docs = list(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35fc18",
   "metadata": {},
   "source": [
    "## Build the Document-Term Matrix (DTM)\n",
    "\n",
    "Now we turn our loaded text documents into a Document-Term Matrix (DTM) using the Lexos `DTM` class.\n",
    "\n",
    "Each row in the DTM represents a term, and each column represents a document. The values inside the matrix tell us how important each word is in each document.\n",
    "\n",
    "For this example, we'll customize how the matrix is built using the following settings:\n",
    "\n",
    "- `tf_type=\"linear\"`: Uses raw term frequencies (how often a word appears).\n",
    "- `idf_type=\"smooth\"`: Reduces the impact of words that appear in many documents.\n",
    "- `norm=\"l2\"`: Normalizes values for fair comparison across different-length documents.\n",
    "- `min_df=2`: Removes words that appear in fewer than 2 documents.\n",
    "- `max_n_terms=100`: Keeps only the top 100 most important terms.\n",
    "\n",
    "The `.to_df()` function converts the matrix into a readable table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12840034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DTM class\n",
    "from lexos.dtm import DTM\n",
    "\n",
    "# Create a Document-Term Matrix (DTM) with specific settings\n",
    "dtm = DTM(\n",
    "    tf_type = \"linear\",\n",
    "    idf_type = \"smooth\",\n",
    "    norm=\"l2\",\n",
    "    min_df=2,\n",
    "    max_n_terms=100,\n",
    ")\n",
    "\n",
    "# Build the DTM using the loaded documents and their labels\n",
    "dtm(docs=docs, labels=loader.names)\n",
    "\n",
    "# Convert the DTM to a DataFrame for easier viewing and analysis\n",
    "df = dtm.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf7074",
   "metadata": {},
   "source": [
    "## Perform K-Means Clustering\n",
    "\n",
    "Now we’re ready to use the k-means clustering module from Lexos. This tool will analyze your document-term matrix and group the documents into clusters based on how similar their word usage is.\n",
    "\n",
    "Here, we create a `KMeans` object and pass it the DTM we created earlier. When we call the object with our chosen number of clusters (_k_), we get back an array in which each item corresponds to one of our documents (in the order submitted) and the number is the cluster to which it has been assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KMeans class\n",
    "from lexos.cluster import KMeans\n",
    "\n",
    "labels = dtm.labels  # Get the labels from the DTM\n",
    "\n",
    "# Create the clustering object using our DTM and 4 clusters\n",
    "kmeans = KMeans(dtm=dtm, labels=labels, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc11b90",
   "metadata": {},
   "source": [
    "You can save the data from you cluster analysis to a CSV file with `kmeans.to_csv(\"filename.csv\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c528ed",
   "metadata": {},
   "source": [
    "### `KMeans` Settings\n",
    "\n",
    "The `KMeans` class allows you to fine-tune how the clustering is performed by setting these optional parameters:\n",
    "\n",
    "- `k`: The number of clusters to create.\n",
    "- `init`: This is the initialization strategy, which can be \"k-means++\" or \"random\". \"k-Means++\" selects initial cluster centers using a weighted probability distribution to speed up convergence. This can help can help to constrain the initial placement of the centroids. The \"random\" option chooses K observations at random from the data to serve as the initial centroids. The default is \"k-means++\".\n",
    "- `max_iter`: The maximum number of iterations of the k-means algorithm for a single run. The default is 300.\n",
    "- `n_init`: The number of times (N) the k-means algorithm will be run with different centroid seeds (the tolerance for convergence). The final results will be the best output of those N consecutive runs. The default is 10.\n",
    "- `tol` The relative tolerance with respect to inertia to declare convergence. The default is 0.0001.\n",
    "- `random_state`: A number to use as the initial seed to insure that the results are reproducible. The default is 42.\n",
    "```\n",
    "\n",
    "Try changing some of the settings in the previous cell to see how they affect the clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18980e4",
   "metadata": {},
   "source": [
    "### Choosing the Best Number of Clusters (k)\n",
    "\n",
    "K-means clustering requires you to choose a number of clusters (_k_) before you begin your analysis. We can decide on an arbitrary number, or we can leverage some statisical guidance. One way to do this is by using an elbow plot.\n",
    "\n",
    "The elbow plot shows how much better the clustering gets as we increase _k_. At some point, the improvement slows down — this point is called the elbow, and it's usually a good choice for _k_.\n",
    "\n",
    "You can generate an elblow plot with the `elbow_plot()` method, submitting a range of numbers (between 1 and 10 in the example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd34e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.elbow_plot(k_range=range(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ffa19",
   "metadata": {},
   "source": [
    "In the graph above:\n",
    "\n",
    "- The x-axis shows the number of clusters (_k_) we tried.\n",
    "- The y-axis shows the inertia (or within-cluster sum of squares), which measures how compact the clusters are.\n",
    "- Lower values of inertia mean tighter, more defined clusters.\n",
    "- The \"elbow\" is where the curve sharply changes direction — it’s the point beyond which adding more clusters doesn't significantly reduce inertia.\n",
    "\n",
    "In our case, the elbow occurs at `k = 4`, meaning that 4 clusters is a good balance between under- and over-clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe3ef8",
   "metadata": {},
   "source": [
    "## Visualize Clusters\n",
    "\n",
    "Lexos provides three methods of visualizing the results of a k-means cluster analysis. In each case, Lexos first applies PCA (Principal Component Analysis) to reduce the dimensions of the data so it can be viewed in a 2D or 3D graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1f264",
   "metadata": {},
   "source": [
    "## Scatter Plots\n",
    "\n",
    "Scatter plots use represent document clusters as dots in Cartesian space. Each dot is a document, and colors represent clusters.\n",
    "\n",
    "You can create a two-dimensional scatter plot as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90117c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.scatter(dim=2, title=\"KMeans Clustering 2D Plot\", show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e128863",
   "metadata": {},
   "source": [
    "Run your mouse over the plot to see the toolbar, which includes an option to save the image as a `.png` file.\n",
    "\n",
    "Set `show=False` if you want to save the plot to a variable or file without saving it.\n",
    "\n",
    "You can save the image programmatically with `kmeans.save(\"filename.png\")`. The format of your output (e.g. `.jpg`, `.pdf`, `.svg`) will be determined by the extension in your filename. You can also set `html=True` to save your image as a web page (e.g. `kmeans.save(\"filename.html\", html=True)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506c4c0",
   "metadata": {},
   "source": [
    "In some cases, documents in a two-dimensional plot can overlap, making the plot hard to read. In this case, you might want to try a three-dimensional plot. You can do this by setting `dim=3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2fd59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.scatter(dim=3, title=\"KMeans Clustering 3D Plot\", show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f02cc",
   "metadata": {},
   "source": [
    "The toolbar in three-dimensional plots has additional options for helping you manipulate the image.\n",
    "\n",
    "You can also save the image using the same methods described above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd0b8ef",
   "metadata": {},
   "source": [
    "### Voronoi Diagrams\n",
    "\n",
    "A Voronoi diagram shows how the clustering algorithm \"divides\" the PCA-reduced 2D space into decision regions.\n",
    "\n",
    "Each colored area represents the region closest to one of the cluster centroids. The black X's mark the calculated centroids. Your documents are plotted as colored dots based on which cluster they belong to.\n",
    "\n",
    "This visualization is useful for understanding how clearly separated your clusters are — especially when the groups overlap or are close together.\n",
    "\n",
    "You can generate a Voronoi diagram as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec71d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.voronoi(show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30ba31",
   "metadata": {},
   "source": [
    "As with scatter plots, there is a Plotly toolbar when you run your mouse over the diagram.\n",
    "\n",
    "You can also save the image using the same methods described above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
