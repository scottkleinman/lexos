{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13eb0543-86b4-40a3-93fc-969242b79349",
   "metadata": {},
   "source": [
    "# Lexos Termite Plots\n",
    "\n",
    "This script does the following:\n",
    "\n",
    "1. Creates spaCy docs from a list of text files.\n",
    "2. Converts the tokens to lower case and filters them to remove digits, punctuation, and whitespace.\n",
    "3. Creates a DTM based on the filtered tokens.\n",
    "4. Converts the DTM to a pandas dataframe.\n",
    "5. Generates a [termite plot](http://vis.stanford.edu/files/2012-Termite-AVI.pdf) from the dataframe showing the salience of each term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bf0c8-bb4c-4cd7-aca5-4e30dd94c522",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure a list of file paths, the labels you wish to use for each document, and the language model you wish to use to parse the texts.\n",
    "\n",
    "Note that converting long texts to spaCy docs can take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6c0ea8-f075-4cd5-81a5-61402b5f4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own data\n",
    "data = [\n",
    "    r\"C:\\Users\\jack\\OneDrive\\Documents\\School\\summer22\\LexosRepo\\lexos\\tests\\test_data\\txt\\Austen_Pride.txt\",\n",
    "    r\"C:\\Users\\jack\\OneDrive\\Documents\\School\\summer22\\LexosRepo\\lexos\\tests\\test_data\\txt\\Austen_Pride.txt\"\n",
    "]\n",
    "labels = [\"Pride\", \"Sense\"]\n",
    "model = \"en_core_web_sm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb3b32-adca-49ee-88b0-0d907c29de90",
   "metadata": {},
   "source": [
    "## Import Lexos API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a065ff-e19c-4b1c-acda-e0b2222b54fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack\\OneDrive\\Documents\\school\\summer22\\LexosRepo\\lexos\\lexos\n"
     ]
    }
   ],
   "source": [
    "# Set local import path\n",
    "import os\n",
    "import sys\n",
    "LEXOS_PATH = \"lexos\"\n",
    "if \"NOTEBOOK_INITIATED_FLAG\" not in globals():\n",
    "    NOTEBOOK_INITIATED_FLAG = True\n",
    "    try:\n",
    "        module_path = os.path.join(os.path.dirname(__file__), os.pardir)\n",
    "    except:\n",
    "        module_path = os.path.abspath(os.path.join(LEXOS_PATH))\n",
    "        %cd lexos\n",
    "        %pwd\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "        \n",
    "# Import Lexos API modules\n",
    "from lexos.io.basic import Loader\n",
    "from lexos import tokenizer\n",
    "from lexos.dtm import DTM\n",
    "try:\n",
    "    from textacy.viz import termite\n",
    "except ImportError:\n",
    "    print(\"Please install textacy to use create termite plots.\")\n",
    "    print('Use `pip install textacy` or `conda install -c conda-forge textacy`.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb3bfd-0393-451d-82d5-e98a4ade28c6",
   "metadata": {},
   "source": [
    "## Load Texts and Convert to spaCy Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e8055-22b9-4f83-bc0a-ece1d20c58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loader and load the data\n",
    "loader = Loader()\n",
    "loader.load(data)\n",
    "\n",
    "# Make the docs -- currently takes a long time with full novels\n",
    "docs = tokenizer.make_docs(loader.texts, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bcf348-d0e1-4e94-9c7a-8ba6158ecc92",
   "metadata": {},
   "source": [
    "## Filter the Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d25bb-cd4f-42b1-a139-0caa4b0a13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "    [\n",
    "        token.norm_ for token in doc  # lower case\n",
    "        if not token.is_space         # not space\n",
    "        and not token.is_punct        # not punctuation\n",
    "        and not token.is_stop         # not stop word\n",
    "        and not token.is_digit        # not digit\n",
    "        and token.pos_ != \"PROPN\"     # not proper noun\n",
    "    ] for doc in docs\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62f4d8-131f-4052-a5c0-e44d84486fb8",
   "metadata": {},
   "source": [
    "## Build DTM and Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3233b1-0782-4807-939d-d5845178899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the DTM and get it in a dataframe\n",
    "dtm = DTM(tokens, labels)\n",
    "df = dtm.get_table()\n",
    "\n",
    "# Set the terms column as the index\n",
    "df = df.set_index(\"terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e235050-28f2-406b-bc48-1421b7dc3ddf",
   "metadata": {},
   "source": [
    "## Create Termite Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c3cea-f785-450d-9355-6629a83207d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "termite.termite_df_plot(df, highlight_topics=[\"Emma\"], n_terms=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580325ec-002e-4e30-87ca-ab422dcd536d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
